WARNING: clusterbot not installed. Can't notify slack.
2021-08-12 07:56:37  Turning off  compiler optimizations for fast compilation
                     Suppressing compiler warnings
                     Running with the following prefs combinations:

                     1 run with default preferences
                     

Running tests in /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2, /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/brian2cuda/tests  (including long tests)
Running Brian version 2.2.2.1+git from '/home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2'
Testing standalone

Testing standalone device "cuda_standalone"
Running standalone-compatible standard tests (single run statement)
============================= test session starts ==============================
platform linux2 -- Python 2.7.18, pytest-4.6.4, py-1.10.0, pluggy-0.12.0 -- /home/denis/.conda/envs/b2c/bin/python
cachedir: .pytest_cache
rootdir: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository, inifile: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2/tests/pytest.ini
collecting ... collected 698 items / 698 deselected

=============================== warnings summary ===============================
/home/denis/.conda/envs/b2c/lib/python2.7/site-packages/_pytest/mark/structures.py:334
  /home/denis/.conda/envs/b2c/lib/python2.7/site-packages/_pytest/mark/structures.py:334: PytestUnknownMarkWarning: Unknown pytest.mark.cuda_standalone - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html
    PytestUnknownMarkWarning,

-- Docs: https://docs.pytest.org/en/latest/warnings.html
================== 698 deselected, 1 warnings in 1.93 seconds ==================
Running standalone-compatible standard tests (multiple run statements)
============================= test session starts ==============================
platform linux2 -- Python 2.7.18, pytest-4.6.4, py-1.10.0, pluggy-0.12.0 -- /home/denis/.conda/envs/b2c/bin/python
cachedir: .pytest_cache
rootdir: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository, inifile: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2/tests/pytest.ini
collecting ... collected 698 items / 698 deselected

======================== 698 deselected in 1.72 seconds ========================
Running standalone-specific tests
============================= test session starts ==============================
platform linux2 -- Python 2.7.18, pytest-4.6.4, py-1.10.0, pluggy-0.12.0 -- /home/denis/.conda/envs/b2c/bin/python
cachedir: .pytest_cache
rootdir: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository, inifile: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2/tests/pytest.ini
collecting ... collected 698 items / 692 deselected / 6 selected

../../tests/test_gpu_detection.py::test_wrong_cuda_path_error PASSED     [ 16%]
../../tests/test_gpu_detection.py::test_manual_setting_compute_capability None
FAILED [ 33%]
../../tests/test_gpu_detection.py::test_unsupported_compute_capability_error None
FAILED [ 50%]
../../tests/test_gpu_detection.py::test_warning_compute_capability_set_twice None
FAILED [ 66%]
../../tests/test_gpu_detection.py::test_no_gpu_detection_preference_error PASSED [ 83%]
../../tests/test_gpu_detection.py::test_no_gpu_detection_preference None
FAILED [100%]

=================================== FAILURES ===================================
____________________ test_manual_setting_compute_capability ____________________

    @pytest.mark.cuda_standalone
    @pytest.mark.standalone_only
    def test_manual_setting_compute_capability():
        set_device("cuda_standalone", directory=None)
        compute_capability_pref = '3.5'
        prefs.devices.cuda_standalone.cuda_backend.compute_capability = float(compute_capability_pref)
        with catch_logs(log_level=logging.INFO) as logs:
>           run(0*ms)

../../tests/test_gpu_detection.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
../../device.py:1489: in network_run
    self.build(direct_call=False, **self.build_options)
../../device.py:1224: in build
    self.generate_main_source(self.writer)
../../device.py:575: in generate_main_source
    self.gpu_id, self.compute_capability = select_gpu()
../../utils/gputools.py:119: in select_gpu
    gpu_id, compute_capability = _select_gpu()
../../utils/gputools.py:268: in _select_gpu
    gpu_id, compute_capability = get_best_gpu()
../../utils/gputools.py:446: in get_best_gpu
    compute_capability = get_compute_capability(gpu_id)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

gpu_id = 0

    def get_compute_capability(gpu_id):
        """
        Get compute capability of GPU with ID `gpu_id`. Returns a float (e.g. `6.1`).
        """
        gpu_list = get_available_gpus()
        cuda_path = get_cuda_path()
        device_query_path = os.path.join(cuda_path, "extras", "demo_suite", "deviceQuery")
        if not os.path.exists(device_query_path):
            # Note: If `deviceQuery` is not reliably available of user systems, we could
            # 1. use this github gist to scrape compute capabilities for GPU names from the
            #    nvidia website:
            #    https://gist.github.com/huitseeker/b2c79e5b763d58b06b9985de2b3c0d4d
            # 2. add a preference to point to the self-compiled binary?
            raise RuntimeError(
                "Couldn't find `{}` binary to detect the compute capability of "
                "the GPU. Please open an issue at "
                "https://github.com/brian-team/brian2cuda/issues/new. To continue, you can "
                "set the compute capability manually via "
                "`prefs.devices.cuda_standalone.cuda_backend.compute_capability` (visit "
                "https://developer.nvidia.com/cuda-gpus to find the compute capability of "
>               "your GPU).".format(device_query_path)
            )
E           RuntimeError: Couldn't find `/tmp/extras/demo_suite/deviceQuery` binary to detect the compute capability of the GPU. Please open an issue at https://github.com/brian-team/brian2cuda/issues/new. To continue, you can set the compute capability manually via `prefs.devices.cuda_standalone.cuda_backend.compute_capability` (visit https://developer.nvidia.com/cuda-gpus to find the compute capability of your GPU).

../../utils/gputools.py:407: RuntimeError
__________________ test_unsupported_compute_capability_error ___________________

    @pytest.mark.cuda_standalone
    @pytest.mark.standalone_only
    def test_unsupported_compute_capability_error():
        set_device("cuda_standalone", directory=None)
        prefs.devices.cuda_standalone.cuda_backend.compute_capability = 2.0
        with pytest.raises(NotImplementedError):
>           run(0*ms)

../../tests/test_gpu_detection.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
../../device.py:1489: in network_run
    self.build(direct_call=False, **self.build_options)
../../device.py:1224: in build
    self.generate_main_source(self.writer)
../../device.py:575: in generate_main_source
    self.gpu_id, self.compute_capability = select_gpu()
../../utils/gputools.py:119: in select_gpu
    gpu_id, compute_capability = _select_gpu()
../../utils/gputools.py:268: in _select_gpu
    gpu_id, compute_capability = get_best_gpu()
../../utils/gputools.py:446: in get_best_gpu
    compute_capability = get_compute_capability(gpu_id)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

gpu_id = 0

    def get_compute_capability(gpu_id):
        """
        Get compute capability of GPU with ID `gpu_id`. Returns a float (e.g. `6.1`).
        """
        gpu_list = get_available_gpus()
        cuda_path = get_cuda_path()
        device_query_path = os.path.join(cuda_path, "extras", "demo_suite", "deviceQuery")
        if not os.path.exists(device_query_path):
            # Note: If `deviceQuery` is not reliably available of user systems, we could
            # 1. use this github gist to scrape compute capabilities for GPU names from the
            #    nvidia website:
            #    https://gist.github.com/huitseeker/b2c79e5b763d58b06b9985de2b3c0d4d
            # 2. add a preference to point to the self-compiled binary?
            raise RuntimeError(
                "Couldn't find `{}` binary to detect the compute capability of "
                "the GPU. Please open an issue at "
                "https://github.com/brian-team/brian2cuda/issues/new. To continue, you can "
                "set the compute capability manually via "
                "`prefs.devices.cuda_standalone.cuda_backend.compute_capability` (visit "
                "https://developer.nvidia.com/cuda-gpus to find the compute capability of "
>               "your GPU).".format(device_query_path)
            )
E           RuntimeError: Couldn't find `/tmp/extras/demo_suite/deviceQuery` binary to detect the compute capability of the GPU. Please open an issue at https://github.com/brian-team/brian2cuda/issues/new. To continue, you can set the compute capability manually via `prefs.devices.cuda_standalone.cuda_backend.compute_capability` (visit https://developer.nvidia.com/cuda-gpus to find the compute capability of your GPU).

../../utils/gputools.py:407: RuntimeError
__________________ test_warning_compute_capability_set_twice ___________________

    @pytest.mark.cuda_standalone
    @pytest.mark.standalone_only
    def test_warning_compute_capability_set_twice():
        set_device("cuda_standalone", directory=None)
        prefs.devices.cuda_standalone.cuda_backend.compute_capability = 3.5
        prefs.devices.cuda_standalone.cuda_backend.extra_compile_args_nvcc.append('-arch=sm_37')
        with catch_logs() as logs:
>           run(0*ms)

../../tests/test_gpu_detection.py:75: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
../../device.py:1489: in network_run
    self.build(direct_call=False, **self.build_options)
../../device.py:1224: in build
    self.generate_main_source(self.writer)
../../device.py:575: in generate_main_source
    self.gpu_id, self.compute_capability = select_gpu()
../../utils/gputools.py:119: in select_gpu
    gpu_id, compute_capability = _select_gpu()
../../utils/gputools.py:268: in _select_gpu
    gpu_id, compute_capability = get_best_gpu()
../../utils/gputools.py:446: in get_best_gpu
    compute_capability = get_compute_capability(gpu_id)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

gpu_id = 0

    def get_compute_capability(gpu_id):
        """
        Get compute capability of GPU with ID `gpu_id`. Returns a float (e.g. `6.1`).
        """
        gpu_list = get_available_gpus()
        cuda_path = get_cuda_path()
        device_query_path = os.path.join(cuda_path, "extras", "demo_suite", "deviceQuery")
        if not os.path.exists(device_query_path):
            # Note: If `deviceQuery` is not reliably available of user systems, we could
            # 1. use this github gist to scrape compute capabilities for GPU names from the
            #    nvidia website:
            #    https://gist.github.com/huitseeker/b2c79e5b763d58b06b9985de2b3c0d4d
            # 2. add a preference to point to the self-compiled binary?
            raise RuntimeError(
                "Couldn't find `{}` binary to detect the compute capability of "
                "the GPU. Please open an issue at "
                "https://github.com/brian-team/brian2cuda/issues/new. To continue, you can "
                "set the compute capability manually via "
                "`prefs.devices.cuda_standalone.cuda_backend.compute_capability` (visit "
                "https://developer.nvidia.com/cuda-gpus to find the compute capability of "
>               "your GPU).".format(device_query_path)
            )
E           RuntimeError: Couldn't find `/tmp/extras/demo_suite/deviceQuery` binary to detect the compute capability of the GPU. Please open an issue at https://github.com/brian-team/brian2cuda/issues/new. To continue, you can set the compute capability manually via `prefs.devices.cuda_standalone.cuda_backend.compute_capability` (visit https://developer.nvidia.com/cuda-gpus to find the compute capability of your GPU).

../../utils/gputools.py:407: RuntimeError
_______________________ test_no_gpu_detection_preference _______________________

    @pytest.mark.cuda_standalone
    @pytest.mark.standalone_only
    def test_no_gpu_detection_preference():
        set_device("cuda_standalone", directory=None)
        # Test that disabling gpu detection works when setting gpu_id and compute_capability
        prefs.devices.cuda_standalone.cuda_backend.detect_gpus = False
        prefs.devices.cuda_standalone.cuda_backend.gpu_id = 0
        prefs.devices.cuda_standalone.cuda_backend.compute_capability = 6.1
>       run(0*ms)

../../tests/test_gpu_detection.py:103: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
../../device.py:1489: in network_run
    self.build(direct_call=False, **self.build_options)
../../device.py:1254: in build
    disable_asserts)
../../device.py:1008: in generate_makefile
    nvcc_path = get_nvcc_path()
../../utils/gputools.py:59: in get_nvcc_path
    _cuda_installation["nvcc_path"] = _get_nvcc_path()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _get_nvcc_path():
        # TODO: Check if NVCC is specific to cupy and if we want to support it?
        # If so, make sure cuda_path and nvcc_path fit together, see:
        # https://github.com/cupy/cupy/blob/cb29c07ccbae346841adb3c8bfa33aba463e2588/install/build.py#L65-L70
        #nvcc = os.environ.get("NVCC", None)
        #if nvcc:
        #    return distutils.util.split_quoted(nvcc)
    
        cuda_path = get_cuda_path()
    
        compiler, _ = get_compiler_and_args()
        if compiler == "msvc":  # Windows
            nvcc_bin = "bin/nvcc.exe"
        else:  # Unix
            nvcc_bin = "bin/nvcc"
    
        nvcc_path = os.path.join(cuda_path, nvcc_bin)
        if not os.path.exists(nvcc_path):
>           raise RuntimeError("Couldn't find `nvcc` binary in {}.".format(nvcc_path))
E           RuntimeError: Couldn't find `nvcc` binary in /tmp/bin/nvcc.

../../utils/gputools.py:241: RuntimeError
----------------------------- Captured stderr call -----------------------------
WARNING    GPU architecture for compilation was specified via `prefs.devices.cuda_standalone.cuda_backend.compute_capability` and `prefs.devices.cuda_standalone.cuda_backend.extra_compile_args_nvcc`. `prefs.devices.cuda_standalone.cuda_backend.compute_capability` will be ignored. To get rid of this warning, set `prefs.devices.cuda_standalone.brian_backend.compute_capability` to it's default value `None` [brian2.devices.cuda_standalone]
============== 4 failed, 2 passed, 692 deselected in 4.25 seconds ==============
ERROR: 3/3 test suite(s) did not complete successfully (see above).
2021-08-12 07:56:46  
TARGET: CUDA_STANDALONE
2021-08-12 07:56:46  
FINISHED ALL RUNS

                     1/1 CONFIGURATIONS FAILED:
                     	1. run
                     		default preferences
Test suite took 0 h 0 m 9 s.
