WARNING: clusterbot not installed. Can't notify slack.
2021-08-11 09:21:10  Turning off  compiler optimizations for fast compilation
                     Suppressing compiler warnings
                     Running with the following prefs combinations:

                     1 run with default preferences
                     

Running tests in /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2, /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/brian2cuda/tests  (including long tests)
Running Brian version 2.2.2.1+git from '/home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2'
Testing standalone

Testing standalone device "cuda_standalone"
Running standalone-compatible standard tests (single run statement)
============================= test session starts ==============================
platform linux2 -- Python 2.7.18, pytest-4.6.4, py-1.10.0, pluggy-0.12.0 -- /home/denis/.conda/envs/b2c/bin/python
cachedir: .pytest_cache
rootdir: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2, inifile: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2/tests/pytest.ini
collecting ... collected 695 items / 672 deselected / 23 selected

../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_rand <- ../../../brian2cuda/tests/test_random_number_generation.py PASSED [  4%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_values_set_synapses_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [  8%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_values_set_synapses_fixed_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 13%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_values_init_synapses_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 17%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_binomial_values_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 21%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_binomial_values_fixed_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 26%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_binomial_values_set_synapses_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 30%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_binomial_values_set_synapses_fixed_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 34%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_binomial_values_init_synapses_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 39%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_binomial_set_template_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 43%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_binomial_poisson_scalar_lambda_values_set_synapses_fixed_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 47%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_binomial_poisson_variable_lambda_values_set_synapses_fixed_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 52%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_scalar_lambda_values_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 56%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_variable_lambda_values_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 60%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_scalar_lambda_values_fixed_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 65%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_variable_lambda_values_fixed_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 69%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_scalar_lambda_values_set_synapses_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 73%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_variable_lambda_values_set_synapses_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 78%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_scalar_lambda_values_set_synapses_fixed_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 82%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_variable_lambda_values_set_synapses_fixed_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 86%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_values_init_synapses_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 91%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_scalar_lambda_set_template_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 95%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_variable_lambda_set_template_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [100%]

=================================== FAILURES ===================================
_________________ test_random_values_set_synapses_random_seed __________________

    @pytest.mark.standalone_compatible
    def test_random_values_set_synapses_random_seed():
        G = NeuronGroup(10, 'z : 1')
        S = Synapses(G, G, '''v1 : 1
                              v2 : 1''')
        S.connect()
        seed()
        S.v1 = 'rand() + randn()'
        seed()
        S.v2 = 'rand() + randn()'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:463: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), Synapses(c...ateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d04eae90>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
__________________ test_random_values_set_synapses_fixed_seed __________________

    @pytest.mark.standalone_compatible
    def test_random_values_set_synapses_fixed_seed():
        G = NeuronGroup(10, 'z : 1')
        S = Synapses(G, G, '''v1 : 1
                              v2 : 1''')
        S.connect()
        seed(12345678)
        S.v1 = 'rand() + randn()'
        seed(12345678)
        S.v2 = 'rand() + randn()'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:479: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_1'), Synapses...eUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d04eae90>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
____________ test_random_values_init_synapses_fixed_and_random_seed ____________

    @pytest.mark.standalone_compatible
    def test_random_values_init_synapses_fixed_and_random_seed():
        G = NeuronGroup(10, 'z : 1')
    
        seed()
        S1 = Synapses(G, G)
        S1.connect('randn() + 0.5 < rand()')
    
        seed(12345678)
        S2 = Synapses(G, G)
        S2.connect('randn() + 0.5 < rand()')
    
        seed()
        S3 = Synapses(G, G)
        S3.connect('randn() + 0.5 < rand()')
    
        seed(12345678)
        S4 = Synapses(G, G)
        S4.connect('randn() + 0.5 < rand()')
    
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), Synapses(c...ateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d04eae90>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
_______________________ test_binomial_values_random_seed _______________________

    @pytest.mark.standalone_compatible
    def test_binomial_values_random_seed():
        G = NeuronGroup(100, '''v1 : 1
                                v2 : 1''')
        my_f = BinomialFunction(100, 0.1, approximate=False)
        my_f_approximated = BinomialFunction(100, 0.1, approximate=True)
        seed()
        G.v1 = 'my_f() + my_f_approximated()'
        seed()
        G.v2 = 'my_f() + my_f_approximated()'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:580: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_2'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_2_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_2_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d04eae90>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
_______________________ test_binomial_values_fixed_seed ________________________

    @pytest.mark.standalone_compatible
    def test_binomial_values_fixed_seed():
        G = NeuronGroup(100, '''v1 : 1
                                v2 : 1''')
        my_f = BinomialFunction(100, 0.1, approximate=False)
        my_f_approximated = BinomialFunction(100, 0.1, approximate=True)
        seed(12345678)
        G.v1 = 'my_f() + my_f_approximated()'
        seed(12345678)
        G.v2 = 'my_f() + my_f_approximated()'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:596: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d04eae90>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
________________ test_binomial_values_set_synapses_random_seed _________________

    @pytest.mark.standalone_compatible
    def test_binomial_values_set_synapses_random_seed():
        G = NeuronGroup(10, 'z : 1')
        S = Synapses(G, G, '''v1 : 1
                              v2 : 1''')
        S.connect()
    
        my_f = BinomialFunction(100, 0.1, approximate=False)
        my_f_approximated = BinomialFunction(100, 0.1, approximate=True)
    
        seed()
        S.v1 = 'my_f() + my_f_approximated()'
        seed()
        S.v2 = 'my_f() + my_f_approximated()'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:661: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_1'), Synapses...eUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d04eae90>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
_________________ test_binomial_values_set_synapses_fixed_seed _________________

    @pytest.mark.standalone_compatible
    def test_binomial_values_set_synapses_fixed_seed():
        G = NeuronGroup(10, 'z : 1')
        S = Synapses(G, G, '''v1 : 1
                              v2 : 1''')
        S.connect()
    
        my_f = BinomialFunction(100, 0.1, approximate=False)
        my_f_approximated = BinomialFunction(100, 0.1, approximate=True)
    
        seed(12345678)
        S.v1 = 'my_f() + my_f_approximated()'
        seed(12345678)
        S.v2 = 'my_f() + my_f_approximated()'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:681: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), Synapses(c...ateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d0530450>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
___________ test_binomial_values_init_synapses_fixed_and_random_seed ___________

    @pytest.mark.standalone_compatible
    def test_binomial_values_init_synapses_fixed_and_random_seed():
        G = NeuronGroup(10, 'z : 1')
    
        my_f = BinomialFunction(100, 0.1, approximate=False)
        my_f_approximated = BinomialFunction(100, 0.1, approximate=True)
    
        seed()
        S1 = Synapses(G, G)
        S1.connect('my_f() < my_f_approximated()')
    
        seed(12345678)
        S2 = Synapses(G, G)
        S2.connect('my_f() < my_f_approximated()')
    
        seed()
        S3 = Synapses(G, G)
        S3.connect('my_f() < my_f_approximated()')
    
        seed(12345678)
        S4 = Synapses(G, G)
        S4.connect('my_f() < my_f_approximated()')
    
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:757: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_2'), Synapses...eUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_2_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_2_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d0530450>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
________________ test_random_binomial_set_template_random_seed _________________

    @pytest.mark.standalone_compatible
    def test_random_binomial_set_template_random_seed():
        G = NeuronGroup(10, '''v1 : 1
                               v2 : 1''')
        my_f = BinomialFunction(100, 0.1, approximate=False)
        my_f_approximated = BinomialFunction(100, 0.1, approximate=True)
    
        seed()
        G.v1[:8] = 'rand() + randn() + my_f() + my_f_approximated()'
        seed()
        G.v2[:8] = 'rand() + randn() + my_f() + my_f_approximated()'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d0530450>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
__ test_random_binomial_poisson_scalar_lambda_values_set_synapses_fixed_seed ___

    @pytest.mark.standalone_compatible
    def test_random_binomial_poisson_scalar_lambda_values_set_synapses_fixed_seed():
        G = NeuronGroup(10, '''v1 : 1
                               v2 : 1''')
        my_f = BinomialFunction(100, 0.1, approximate=False)
        my_f_approximated = BinomialFunction(100, 0.1, approximate=True)
    
        seed(12345678)
        G.v1[:8] = 'rand() + randn() + my_f() + my_f_approximated() + poisson(5)'
        seed(12345678)
        G.v2[:8] = 'rand() + randn() + my_f() + my_f_approximated() + poisson(5)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:804: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_1'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d0530450>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
_ test_random_binomial_poisson_variable_lambda_values_set_synapses_fixed_seed __

    @pytest.mark.standalone_compatible
    def test_random_binomial_poisson_variable_lambda_values_set_synapses_fixed_seed():
        G = NeuronGroup(10, '''v1 : 1
                               v2 : 1
                               l  : 1''')
        G.l = arange(10)
        my_f = BinomialFunction(100, 0.1, approximate=False)
        my_f_approximated = BinomialFunction(100, 0.1, approximate=True)
    
        seed(12345678)
        G.v1[:8] = 'rand() + randn() + my_f() + my_f_approximated() + poisson(l)'
        seed(12345678)
        G.v2[:8] = 'rand() + randn() + my_f() + my_f_approximated() + poisson(l)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:823: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d0530450>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
________________ test_poisson_scalar_lambda_values_random_seed _________________

    @pytest.mark.standalone_compatible
    def test_poisson_scalar_lambda_values_random_seed():
        G = NeuronGroup(100, '''v1 : 1
                                v2 : 1''')
        seed()
        G.v1 = 'poisson(5)'
        seed()
        G.v2 = 'poisson(5)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:840: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_2'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_2_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_2_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d0530450>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
_______________ test_poisson_variable_lambda_values_random_seed ________________

    @pytest.mark.standalone_compatible
    def test_poisson_variable_lambda_values_random_seed():
        G = NeuronGroup(100, '''v1 : 1
                                v2 : 1
                                x1 : 1
                                x2 : 1
                                l  : 1''')
        G.l = arange(100) / 10
        seed()
        G.v1 = 'poisson(l)'
        seed()
        G.v2 = 'poisson(l)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:858: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d0530450>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
_________________ test_poisson_scalar_lambda_values_fixed_seed _________________

    @pytest.mark.standalone_compatible
    def test_poisson_scalar_lambda_values_fixed_seed():
        G = NeuronGroup(100, '''v1 : 1
                                v2 : 1''')
        seed(12345678)
        G.v1 = 'poisson(5)'
        seed(12345678)
        G.v2 = 'poisson(5)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:872: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_1'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d0530450>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
________________ test_poisson_variable_lambda_values_fixed_seed ________________

    @pytest.mark.standalone_compatible
    def test_poisson_variable_lambda_values_fixed_seed():
        G = NeuronGroup(100, '''v1 : 1
                                v2 : 1
                                l  : 1''')
        G.l = arange(100) / 10
        seed(12345678)
        G.v1 = 'poisson(l)'
        seed(12345678)
        G.v2 = 'poisson(l)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:888: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d0530450>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
__________ test_poisson_scalar_lambda_values_set_synapses_random_seed __________

    @pytest.mark.standalone_compatible
    def test_poisson_scalar_lambda_values_set_synapses_random_seed():
        G = NeuronGroup(10, 'z : 1')
        S = Synapses(G, G, '''v1 : 1
                              v2 : 1''')
        S.connect()
    
        seed()
        S.v1 = 'poisson(5)'
        seed()
        S.v2 = 'poisson(5)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:994: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_2'), Synapses...eUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_2_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_2_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d0530450>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
_________ test_poisson_variable_lambda_values_set_synapses_random_seed _________

    @pytest.mark.standalone_compatible
    def test_poisson_variable_lambda_values_set_synapses_random_seed():
        G = NeuronGroup(10, 'z : 1')
        S = Synapses(G, G, '''v1 : 1
                              v2 : 1
                              l  : 1''')
        S.connect()
        S.l = arange(100) / 10
    
        seed()
        S.v1 = 'poisson(l)'
        seed()
        S.v2 = 'poisson(l)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:1013: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), Synapses(c...ateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d0530450>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
__________ test_poisson_scalar_lambda_values_set_synapses_fixed_seed ___________

    @pytest.mark.standalone_compatible
    def test_poisson_scalar_lambda_values_set_synapses_fixed_seed():
        G = NeuronGroup(10, 'z : 1')
        S = Synapses(G, G, '''v1 : 1
                              v2 : 1''')
        S.connect()
    
        seed(12345678)
        S.v1 = 'poisson(5)'
        seed(12345678)
        S.v2 = 'poisson(5)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:1030: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_1'), Synapses...eUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d0530450>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
_________ test_poisson_variable_lambda_values_set_synapses_fixed_seed __________

    @pytest.mark.standalone_compatible
    def test_poisson_variable_lambda_values_set_synapses_fixed_seed():
        G = NeuronGroup(10, 'z : 1')
        S = Synapses(G, G, '''v1 : 1
                              v2 : 1
                              l  : 1''')
        S.connect()
        S.l = arange(100) / 10
    
        seed(12345678)
        S.v1 = 'poisson(l)'
        seed(12345678)
        S.v2 = 'poisson(l)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:1049: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), Synapses(c...ateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d0530450>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
___________ test_poisson_values_init_synapses_fixed_and_random_seed ____________

    @pytest.mark.standalone_compatible
    def test_poisson_values_init_synapses_fixed_and_random_seed():
        G = NeuronGroup(10, 'l : 1')
        G.l = arange(10)
    
        seed()
        S1 = Synapses(G, G)
        S1.connect('poisson(5) < poisson(l_post + l_pre)')
    
        seed(12345678)
        S2 = Synapses(G, G)
        S2.connect('poisson(5) < poisson(l_post + l_pre)')
    
        seed()
        S3 = Synapses(G, G)
        S3.connect('poisson(5) < poisson(l_post + l_pre)')
    
        seed(12345678)
        S4 = Synapses(G, G)
        S4.connect('poisson(5) < poisson(l_post + l_pre)')
    
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:1166: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_2'), Synapses...eUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_2_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_2_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d0530450>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
_____________ test_poisson_scalar_lambda_set_template_random_seed ______________

    @pytest.mark.standalone_compatible
    def test_poisson_scalar_lambda_set_template_random_seed():
        G = NeuronGroup(10, '''v1 : 1
                               v2 : 1''')
    
        seed()
        G.v1[:8] = 'rand() + randn() + poisson(5)'
        seed()
        G.v2[:8] = 'rand() + randn() + poisson(5)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:1194: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d0530450>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
____________ test_poisson_variable_lambda_set_template_random_seed _____________

    @pytest.mark.standalone_compatible
    def test_poisson_variable_lambda_set_template_random_seed():
        G = NeuronGroup(10, '''v1 : 1
                               v2 : 1
                               l  : 1''')
    
        G.l = arange(10)
        seed()
        G.v1[:8] = 'rand() + randn() + poisson(l)'
        seed()
        G.v2[:8] = 'rand() + randn() + poisson(l)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:1211: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_1'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4d0530450>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
=============================== warnings summary ===============================
/home/denis/.conda/envs/b2c/lib/python2.7/site-packages/_pytest/mark/structures.py:334
  /home/denis/.conda/envs/b2c/lib/python2.7/site-packages/_pytest/mark/structures.py:334: PytestUnknownMarkWarning: Unknown pytest.mark.cuda_standalone - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html
    PytestUnknownMarkWarning,

-- Docs: https://docs.pytest.org/en/latest/warnings.html
======= 22 failed, 1 passed, 672 deselected, 1 warnings in 16.32 seconds =======
Running standalone-compatible standard tests (multiple run statements)
============================= test session starts ==============================
platform linux2 -- Python 2.7.18, pytest-4.6.4, py-1.10.0, pluggy-0.12.0 -- /home/denis/.conda/envs/b2c/bin/python
cachedir: .pytest_cache
rootdir: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2, inifile: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2/tests/pytest.ini
collecting ... collected 695 items / 682 deselected / 13 selected

../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_number_generation_with_multiple_runs <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [  7%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_values_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 15%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_scalar_values_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 23%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_vectorized_values_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 30%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_values_codeobject_every_tick <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 38%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_binomial_values <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 46%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_values_synapse_dynamics_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 53%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_binomial_values_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 61%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_binomial_values_synapse_dynamics_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 69%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_scalar_lambda_values_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 76%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_variable_lambda_values_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 84%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_scalar_lambda_values_synapse_dynamics_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 92%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_variable_lambda_values_synapse_dynamics_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [100%]

=================================== FAILURES ===================================
_______________ test_random_number_generation_with_multiple_runs _______________

    @pytest.mark.standalone_compatible
    @pytest.mark.multiple_runs
    def test_random_number_generation_with_multiple_runs():
        G = NeuronGroup(1000, 'dv/dt = rand() : second')
        mon = StateMonitor(G, 'v', record=True)
    
        run(1*defaultclock.dt)
        run(2*defaultclock.dt)
>       device.build(direct_call=False, **device.build_options)

../../tests/test_random_number_generation.py:216: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
directory = None, compile = True, run = True, debug = False, clean = False
with_output = False, disable_asserts = False, additional_source_files = None
run_args = None, direct_call = False, kwds = {}

    def build(self, directory='output',
              compile=True, run=True, debug=False, clean=False,
              with_output=True, disable_asserts=False,
              additional_source_files=None,
              run_args=None, direct_call=True, **kwds):
        '''
        Build the project
    
        TODO: more details
    
        Parameters
        ----------
        directory : str, optional
            The output directory to write the project to, any existing files
            will be overwritten. If the given directory name is ``None``, then
            a temporary directory will be used (used in the test suite to avoid
            problems when running several tests in parallel). Defaults to
            ``'output'``.
        compile : bool, optional
            Whether or not to attempt to compile the project. Defaults to
            ``True``.
        run : bool, optional
            Whether or not to attempt to run the built project if it
            successfully builds. Defaults to ``True``.
        debug : bool, optional
            Whether to compile in debug mode. Defaults to ``False``.
        with_output : bool, optional
            Whether or not to show the ``stdout`` of the built program when run.
            Output will be shown in case of compilation or runtime error.
            Defaults to ``True``.
        clean : bool, optional
            Whether or not to clean the project before building. Defaults to
            ``False``.
        additional_source_files : list of str, optional
            A list of additional ``.cu`` files to include in the build.
        direct_call : bool, optional
            Whether this function was called directly. Is used internally to
            distinguish an automatic build due to the ``build_on_run`` option
            from a manual ``device.build`` call.
        '''
        if self.build_on_run and direct_call:
            raise RuntimeError('You used set_device with build_on_run=True '
                               '(the default option), which will automatically '
                               'build the simulation at the first encountered '
                               'run call - do not call device.build manually '
                               'in this case. If you want to call it manually, '
                               'e.g. because you have multiple run calls, use '
                               'set_device with build_on_run=False.')
        if self.has_been_run:
>           raise RuntimeError('The network has already been built and run '
                               'before. To build several simulations in '
                               'the same script, call "device.reinit()" '
                               'and "device.activate()". Note that you '
                               'will have to set build options (e.g. the '
                               'directory) and defaultclock.dt again.')
E           RuntimeError: The network has already been built and run before. To build several simulations in the same script, call "device.reinit()" and "device.activate()". Note that you will have to set build options (e.g. the directory) and defaultclock.dt again.

../../device.py:1094: RuntimeError
___________________ test_random_values_fixed_and_random_seed ___________________

    @pytest.mark.standalone_compatible
    @pytest.mark.multiple_runs
    def test_random_values_fixed_and_random_seed():
        G = NeuronGroup(10, 'dv/dt = -v/(10*ms) + 0.1*xi/sqrt(ms) : 1')
        mon = StateMonitor(G, 'v', record=True)
    
        # first run
        seed(13579)
        G.v = 'rand()'
        seed()
        run(2*defaultclock.dt)
    
        # second run
        seed(13579)
        G.v = 'rand()'
        seed()
        run(2*defaultclock.dt)
    
>       device.build(direct_call=False, **device.build_options)

../../tests/test_random_number_generation.py:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
directory = None, compile = True, run = True, debug = False, clean = False
with_output = False, disable_asserts = False, additional_source_files = None
run_args = None, direct_call = False, kwds = {}

    def build(self, directory='output',
              compile=True, run=True, debug=False, clean=False,
              with_output=True, disable_asserts=False,
              additional_source_files=None,
              run_args=None, direct_call=True, **kwds):
        '''
        Build the project
    
        TODO: more details
    
        Parameters
        ----------
        directory : str, optional
            The output directory to write the project to, any existing files
            will be overwritten. If the given directory name is ``None``, then
            a temporary directory will be used (used in the test suite to avoid
            problems when running several tests in parallel). Defaults to
            ``'output'``.
        compile : bool, optional
            Whether or not to attempt to compile the project. Defaults to
            ``True``.
        run : bool, optional
            Whether or not to attempt to run the built project if it
            successfully builds. Defaults to ``True``.
        debug : bool, optional
            Whether to compile in debug mode. Defaults to ``False``.
        with_output : bool, optional
            Whether or not to show the ``stdout`` of the built program when run.
            Output will be shown in case of compilation or runtime error.
            Defaults to ``True``.
        clean : bool, optional
            Whether or not to clean the project before building. Defaults to
            ``False``.
        additional_source_files : list of str, optional
            A list of additional ``.cu`` files to include in the build.
        direct_call : bool, optional
            Whether this function was called directly. Is used internally to
            distinguish an automatic build due to the ``build_on_run`` option
            from a manual ``device.build`` call.
        '''
        if self.build_on_run and direct_call:
            raise RuntimeError('You used set_device with build_on_run=True '
                               '(the default option), which will automatically '
                               'build the simulation at the first encountered '
                               'run call - do not call device.build manually '
                               'in this case. If you want to call it manually, '
                               'e.g. because you have multiple run calls, use '
                               'set_device with build_on_run=False.')
        if self.has_been_run:
>           raise RuntimeError('The network has already been built and run '
                               'before. To build several simulations in '
                               'the same script, call "device.reinit()" '
                               'and "device.activate()". Note that you '
                               'will have to set build options (e.g. the '
                               'directory) and defaultclock.dt again.')
E           RuntimeError: The network has already been built and run before. To build several simulations in the same script, call "device.reinit()" and "device.activate()". Note that you will have to set build options (e.g. the directory) and defaultclock.dt again.

../../device.py:1094: RuntimeError
_______________ test_poisson_scalar_values_fixed_and_random_seed _______________

    @pytest.mark.standalone_compatible
    @pytest.mark.multiple_runs
    def test_poisson_scalar_values_fixed_and_random_seed():
        G = NeuronGroup(10, 'dv/dt = -v/(10*ms) + 0.1*poisson(5)/ms : 1')
        mon = StateMonitor(G, 'v', record=True)
    
        # first run
        seed(13579)
        G.v = 'poisson(5)'
        seed()
        run(2*defaultclock.dt)
    
        # second run
        seed(13579)
        G.v = 'poisson(5)'
        seed()
        run(2*defaultclock.dt)
    
>       device.build(direct_call=False, **device.build_options)

../../tests/test_random_number_generation.py:276: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
directory = None, compile = True, run = True, debug = False, clean = False
with_output = False, disable_asserts = False, additional_source_files = None
run_args = None, direct_call = False, kwds = {}

    def build(self, directory='output',
              compile=True, run=True, debug=False, clean=False,
              with_output=True, disable_asserts=False,
              additional_source_files=None,
              run_args=None, direct_call=True, **kwds):
        '''
        Build the project
    
        TODO: more details
    
        Parameters
        ----------
        directory : str, optional
            The output directory to write the project to, any existing files
            will be overwritten. If the given directory name is ``None``, then
            a temporary directory will be used (used in the test suite to avoid
            problems when running several tests in parallel). Defaults to
            ``'output'``.
        compile : bool, optional
            Whether or not to attempt to compile the project. Defaults to
            ``True``.
        run : bool, optional
            Whether or not to attempt to run the built project if it
            successfully builds. Defaults to ``True``.
        debug : bool, optional
            Whether to compile in debug mode. Defaults to ``False``.
        with_output : bool, optional
            Whether or not to show the ``stdout`` of the built program when run.
            Output will be shown in case of compilation or runtime error.
            Defaults to ``True``.
        clean : bool, optional
            Whether or not to clean the project before building. Defaults to
            ``False``.
        additional_source_files : list of str, optional
            A list of additional ``.cu`` files to include in the build.
        direct_call : bool, optional
            Whether this function was called directly. Is used internally to
            distinguish an automatic build due to the ``build_on_run`` option
            from a manual ``device.build`` call.
        '''
        if self.build_on_run and direct_call:
            raise RuntimeError('You used set_device with build_on_run=True '
                               '(the default option), which will automatically '
                               'build the simulation at the first encountered '
                               'run call - do not call device.build manually '
                               'in this case. If you want to call it manually, '
                               'e.g. because you have multiple run calls, use '
                               'set_device with build_on_run=False.')
        if self.has_been_run:
>           raise RuntimeError('The network has already been built and run '
                               'before. To build several simulations in '
                               'the same script, call "device.reinit()" '
                               'and "device.activate()". Note that you '
                               'will have to set build options (e.g. the '
                               'directory) and defaultclock.dt again.')
E           RuntimeError: The network has already been built and run before. To build several simulations in the same script, call "device.reinit()" and "device.activate()". Note that you will have to set build options (e.g. the directory) and defaultclock.dt again.

../../device.py:1094: RuntimeError
_____________ test_poisson_vectorized_values_fixed_and_random_seed _____________

    @pytest.mark.standalone_compatible
    @pytest.mark.multiple_runs
    def test_poisson_vectorized_values_fixed_and_random_seed():
        G = NeuronGroup(10,
                        '''l: 1
                           dv/dt = -v/(10*ms) + 0.1*poisson(l)/ms : 1''')
        G.l = arange(10)
        mon = StateMonitor(G, 'v', record=True)
    
        # first run
        seed(13579)
        G.v = 'poisson(l)'
        seed()
        run(2*defaultclock.dt)
    
        # second run
        seed(13579)
        G.v = 'poisson(l)'
        seed()
        run(2*defaultclock.dt)
    
>       device.build(direct_call=False, **device.build_options)

../../tests/test_random_number_generation.py:311: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
directory = None, compile = True, run = True, debug = False, clean = False
with_output = False, disable_asserts = False, additional_source_files = None
run_args = None, direct_call = False, kwds = {}

    def build(self, directory='output',
              compile=True, run=True, debug=False, clean=False,
              with_output=True, disable_asserts=False,
              additional_source_files=None,
              run_args=None, direct_call=True, **kwds):
        '''
        Build the project
    
        TODO: more details
    
        Parameters
        ----------
        directory : str, optional
            The output directory to write the project to, any existing files
            will be overwritten. If the given directory name is ``None``, then
            a temporary directory will be used (used in the test suite to avoid
            problems when running several tests in parallel). Defaults to
            ``'output'``.
        compile : bool, optional
            Whether or not to attempt to compile the project. Defaults to
            ``True``.
        run : bool, optional
            Whether or not to attempt to run the built project if it
            successfully builds. Defaults to ``True``.
        debug : bool, optional
            Whether to compile in debug mode. Defaults to ``False``.
        with_output : bool, optional
            Whether or not to show the ``stdout`` of the built program when run.
            Output will be shown in case of compilation or runtime error.
            Defaults to ``True``.
        clean : bool, optional
            Whether or not to clean the project before building. Defaults to
            ``False``.
        additional_source_files : list of str, optional
            A list of additional ``.cu`` files to include in the build.
        direct_call : bool, optional
            Whether this function was called directly. Is used internally to
            distinguish an automatic build due to the ``build_on_run`` option
            from a manual ``device.build`` call.
        '''
        if self.build_on_run and direct_call:
            raise RuntimeError('You used set_device with build_on_run=True '
                               '(the default option), which will automatically '
                               'build the simulation at the first encountered '
                               'run call - do not call device.build manually '
                               'in this case. If you want to call it manually, '
                               'e.g. because you have multiple run calls, use '
                               'set_device with build_on_run=False.')
        if self.has_been_run:
>           raise RuntimeError('The network has already been built and run '
                               'before. To build several simulations in '
                               'the same script, call "device.reinit()" '
                               'and "device.activate()". Note that you '
                               'will have to set build options (e.g. the '
                               'directory) and defaultclock.dt again.')
E           RuntimeError: The network has already been built and run before. To build several simulations in the same script, call "device.reinit()" and "device.activate()". Note that you will have to set build options (e.g. the directory) and defaultclock.dt again.

../../device.py:1094: RuntimeError
___________________ test_random_values_codeobject_every_tick ___________________

    @pytest.mark.standalone_compatible
    @pytest.mark.multiple_runs
    def test_random_values_codeobject_every_tick():
        G = NeuronGroup(10, 'dv/dt = -v/(10*ms) + 0.1*xi/sqrt(ms) : 1')
        mon = StateMonitor(G, 'v', record=True)
    
        # first run
        seed(10124)
        G.v = 'rand()'
        run(2*defaultclock.dt)
    
        # second run
        seed(10124)
        G.v = 'rand()'
        run(2*defaultclock.dt)
    
>       device.build(direct_call=False, **device.build_options)

../../tests/test_random_number_generation.py:339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
directory = None, compile = True, run = True, debug = False, clean = False
with_output = False, disable_asserts = False, additional_source_files = None
run_args = None, direct_call = False, kwds = {}

    def build(self, directory='output',
              compile=True, run=True, debug=False, clean=False,
              with_output=True, disable_asserts=False,
              additional_source_files=None,
              run_args=None, direct_call=True, **kwds):
        '''
        Build the project
    
        TODO: more details
    
        Parameters
        ----------
        directory : str, optional
            The output directory to write the project to, any existing files
            will be overwritten. If the given directory name is ``None``, then
            a temporary directory will be used (used in the test suite to avoid
            problems when running several tests in parallel). Defaults to
            ``'output'``.
        compile : bool, optional
            Whether or not to attempt to compile the project. Defaults to
            ``True``.
        run : bool, optional
            Whether or not to attempt to run the built project if it
            successfully builds. Defaults to ``True``.
        debug : bool, optional
            Whether to compile in debug mode. Defaults to ``False``.
        with_output : bool, optional
            Whether or not to show the ``stdout`` of the built program when run.
            Output will be shown in case of compilation or runtime error.
            Defaults to ``True``.
        clean : bool, optional
            Whether or not to clean the project before building. Defaults to
            ``False``.
        additional_source_files : list of str, optional
            A list of additional ``.cu`` files to include in the build.
        direct_call : bool, optional
            Whether this function was called directly. Is used internally to
            distinguish an automatic build due to the ``build_on_run`` option
            from a manual ``device.build`` call.
        '''
        if self.build_on_run and direct_call:
            raise RuntimeError('You used set_device with build_on_run=True '
                               '(the default option), which will automatically '
                               'build the simulation at the first encountered '
                               'run call - do not call device.build manually '
                               'in this case. If you want to call it manually, '
                               'e.g. because you have multiple run calls, use '
                               'set_device with build_on_run=False.')
        if self.has_been_run:
>           raise RuntimeError('The network has already been built and run '
                               'before. To build several simulations in '
                               'the same script, call "device.reinit()" '
                               'and "device.activate()". Note that you '
                               'will have to set build options (e.g. the '
                               'directory) and defaultclock.dt again.')
E           RuntimeError: The network has already been built and run before. To build several simulations in the same script, call "device.reinit()" and "device.activate()". Note that you will have to set build options (e.g. the directory) and defaultclock.dt again.

../../device.py:1094: RuntimeError
_____________________________ test_binomial_values _____________________________

    @pytest.mark.standalone_compatible
    @pytest.mark.multiple_runs
    def test_binomial_values():
        my_f_approximated = BinomialFunction(100, 0.1, approximate=True)
        my_f = BinomialFunction(100, 0.1, approximate=False)
    
        # Test neurongroup every tick objects
        G = NeuronGroup(10,'''dx/dt = my_f_approximated()/ms: 1
                              dy/dt = my_f()/ms: 1''',
                        threshold='True')
        G.run_regularly('''x = my_f_approximated()
                           y = my_f()''')
    
    
        # Test synapses every tick objects (where N is not known at compile time)
        syn = Synapses(G, G,
                       model='''
                             dw/dt = my_f()/ms: 1
                             dv/dt = my_f_approximated()/ms: 1
                             ''',
                       on_pre='''
                              x += w
                              y += v
                              '''
                       # TODO: fails when having binomial here, why?
                       #on_pre='''
                       #       x += w * my_f()
                       #       y += v * my_f_approximated()
                       #       '''
                       )
        # Test synapses generation, which needs host side binomial
        syn.connect(condition='my_f_approximated() < 100')
    
        mon = StateMonitor(G, ['x', 'y'], record=True)
        w_mon = StateMonitor(syn, ['w', 'v'], record=np.arange(100))
    
        def init_group_variables(my_f, my_f_approximated):
            # Test codeobjects run only once outside the network,
            # G.x uses group_variable_set_conditional, G.x[:5] uses group_variable_set
            # Synapse objects (N not known at compile time)
            syn.w = 'my_f()'
            syn.w['i < j'] = 'my_f_approximated()'
            syn.v = 'my_f_approximated()'
            syn.v['i < j'] = 'my_f()'
            # Neurongroup object
            G.x = 'my_f_approximated()'
            G.x[:5] = 'my_f()'
            G.y = 'my_f()'
            G.y[:5] = 'my_f_approximated()'
    
        # first run
        init_group_variables(my_f, my_f_approximated)
        run(2*defaultclock.dt)
    
        # second run
        seed(11400)
        init_group_variables(my_f, my_f_approximated)
        run(2*defaultclock.dt)
    
        # third run
        seed()
        init_group_variables(my_f, my_f_approximated)
        run(2*defaultclock.dt)
    
        # forth run
        seed(11400)
        init_group_variables(my_f, my_f_approximated)
        run(2*defaultclock.dt)
    
>       device.build(direct_call=False, **device.build_options)

../../tests/test_random_number_generation.py:420: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
directory = None, compile = True, run = True, debug = False, clean = False
with_output = False, disable_asserts = False, additional_source_files = None
run_args = None, direct_call = False, kwds = {}

    def build(self, directory='output',
              compile=True, run=True, debug=False, clean=False,
              with_output=True, disable_asserts=False,
              additional_source_files=None,
              run_args=None, direct_call=True, **kwds):
        '''
        Build the project
    
        TODO: more details
    
        Parameters
        ----------
        directory : str, optional
            The output directory to write the project to, any existing files
            will be overwritten. If the given directory name is ``None``, then
            a temporary directory will be used (used in the test suite to avoid
            problems when running several tests in parallel). Defaults to
            ``'output'``.
        compile : bool, optional
            Whether or not to attempt to compile the project. Defaults to
            ``True``.
        run : bool, optional
            Whether or not to attempt to run the built project if it
            successfully builds. Defaults to ``True``.
        debug : bool, optional
            Whether to compile in debug mode. Defaults to ``False``.
        with_output : bool, optional
            Whether or not to show the ``stdout`` of the built program when run.
            Output will be shown in case of compilation or runtime error.
            Defaults to ``True``.
        clean : bool, optional
            Whether or not to clean the project before building. Defaults to
            ``False``.
        additional_source_files : list of str, optional
            A list of additional ``.cu`` files to include in the build.
        direct_call : bool, optional
            Whether this function was called directly. Is used internally to
            distinguish an automatic build due to the ``build_on_run`` option
            from a manual ``device.build`` call.
        '''
        if self.build_on_run and direct_call:
            raise RuntimeError('You used set_device with build_on_run=True '
                               '(the default option), which will automatically '
                               'build the simulation at the first encountered '
                               'run call - do not call device.build manually '
                               'in this case. If you want to call it manually, '
                               'e.g. because you have multiple run calls, use '
                               'set_device with build_on_run=False.')
        if self.has_been_run:
>           raise RuntimeError('The network has already been built and run '
                               'before. To build several simulations in '
                               'the same script, call "device.reinit()" '
                               'and "device.activate()". Note that you '
                               'will have to set build options (e.g. the '
                               'directory) and defaultclock.dt again.')
E           RuntimeError: The network has already been built and run before. To build several simulations in the same script, call "device.reinit()" and "device.activate()". Note that you will have to set build options (e.g. the directory) and defaultclock.dt again.

../../device.py:1094: RuntimeError
----------------------------- Captured stdout call -----------------------------
('debug syn effect mode ', 'target')
('debug syn effect mode ', 'target')
('debug syn effect mode ', 'target')
('debug syn effect mode ', 'target')
__________ test_random_values_synapse_dynamics_fixed_and_random_seed ___________

    @pytest.mark.standalone_compatible
    @pytest.mark.multiple_runs
    def test_random_values_synapse_dynamics_fixed_and_random_seed():
        G = NeuronGroup(10, 'z : 1')
        S = Synapses(G, G, 'dv/dt = -v/(10*ms) + 0.1*xi/sqrt(ms) : 1')
        S.connect()
        mon = StateMonitor(S, 'v', record=range(100))
    
        # first run
        S.v = 0
        seed()
        run(2*defaultclock.dt)
    
        # third run
        S.v = 0
        seed()
        run(2*defaultclock.dt)
    
        # third run
        S.v = 0
        seed(13579)
        run(2*defaultclock.dt)
    
        # fourth run
        S.v = 0
        seed(13579)
        run(2*defaultclock.dt)
    
>       device.build(direct_call=False, **device.build_options)

../../tests/test_random_number_generation.py:514: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
directory = None, compile = True, run = True, debug = False, clean = False
with_output = False, disable_asserts = False, additional_source_files = None
run_args = None, direct_call = False, kwds = {}

    def build(self, directory='output',
              compile=True, run=True, debug=False, clean=False,
              with_output=True, disable_asserts=False,
              additional_source_files=None,
              run_args=None, direct_call=True, **kwds):
        '''
        Build the project
    
        TODO: more details
    
        Parameters
        ----------
        directory : str, optional
            The output directory to write the project to, any existing files
            will be overwritten. If the given directory name is ``None``, then
            a temporary directory will be used (used in the test suite to avoid
            problems when running several tests in parallel). Defaults to
            ``'output'``.
        compile : bool, optional
            Whether or not to attempt to compile the project. Defaults to
            ``True``.
        run : bool, optional
            Whether or not to attempt to run the built project if it
            successfully builds. Defaults to ``True``.
        debug : bool, optional
            Whether to compile in debug mode. Defaults to ``False``.
        with_output : bool, optional
            Whether or not to show the ``stdout`` of the built program when run.
            Output will be shown in case of compilation or runtime error.
            Defaults to ``True``.
        clean : bool, optional
            Whether or not to clean the project before building. Defaults to
            ``False``.
        additional_source_files : list of str, optional
            A list of additional ``.cu`` files to include in the build.
        direct_call : bool, optional
            Whether this function was called directly. Is used internally to
            distinguish an automatic build due to the ``build_on_run`` option
            from a manual ``device.build`` call.
        '''
        if self.build_on_run and direct_call:
            raise RuntimeError('You used set_device with build_on_run=True '
                               '(the default option), which will automatically '
                               'build the simulation at the first encountered '
                               'run call - do not call device.build manually '
                               'in this case. If you want to call it manually, '
                               'e.g. because you have multiple run calls, use '
                               'set_device with build_on_run=False.')
        if self.has_been_run:
>           raise RuntimeError('The network has already been built and run '
                               'before. To build several simulations in '
                               'the same script, call "device.reinit()" '
                               'and "device.activate()". Note that you '
                               'will have to set build options (e.g. the '
                               'directory) and defaultclock.dt again.')
E           RuntimeError: The network has already been built and run before. To build several simulations in the same script, call "device.reinit()" and "device.activate()". Note that you will have to set build options (e.g. the directory) and defaultclock.dt again.

../../device.py:1094: RuntimeError
__________________ test_binomial_values_fixed_and_random_seed __________________

    @pytest.mark.standalone_compatible
    @pytest.mark.multiple_runs
    def test_binomial_values_fixed_and_random_seed():
        my_f = BinomialFunction(100, 0.1, approximate=False)
        my_f_approximated = BinomialFunction(100, 0.1, approximate=True)
    
        G = NeuronGroup(10, 'dv/dt = -v/(10*ms) + 0.1*(my_f() + my_f_approximated())*xi/sqrt(ms) : 1')
        mon = StateMonitor(G, 'v', record=True)
    
        # first run
        G.v = 0
        seed()
        run(2*defaultclock.dt)
    
        # second run
        G.v = 0
        seed()
        run(2*defaultclock.dt)
    
        # third run
        G.v = 0
        seed(13579)
        run(2*defaultclock.dt)
    
        # fourth run
        G.v = 0
        seed(13579)
        run(2*defaultclock.dt)
    
>       device.build(direct_call=False, **device.build_options)

../../tests/test_random_number_generation.py:632: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
directory = None, compile = True, run = True, debug = False, clean = False
with_output = False, disable_asserts = False, additional_source_files = None
run_args = None, direct_call = False, kwds = {}

    def build(self, directory='output',
              compile=True, run=True, debug=False, clean=False,
              with_output=True, disable_asserts=False,
              additional_source_files=None,
              run_args=None, direct_call=True, **kwds):
        '''
        Build the project
    
        TODO: more details
    
        Parameters
        ----------
        directory : str, optional
            The output directory to write the project to, any existing files
            will be overwritten. If the given directory name is ``None``, then
            a temporary directory will be used (used in the test suite to avoid
            problems when running several tests in parallel). Defaults to
            ``'output'``.
        compile : bool, optional
            Whether or not to attempt to compile the project. Defaults to
            ``True``.
        run : bool, optional
            Whether or not to attempt to run the built project if it
            successfully builds. Defaults to ``True``.
        debug : bool, optional
            Whether to compile in debug mode. Defaults to ``False``.
        with_output : bool, optional
            Whether or not to show the ``stdout`` of the built program when run.
            Output will be shown in case of compilation or runtime error.
            Defaults to ``True``.
        clean : bool, optional
            Whether or not to clean the project before building. Defaults to
            ``False``.
        additional_source_files : list of str, optional
            A list of additional ``.cu`` files to include in the build.
        direct_call : bool, optional
            Whether this function was called directly. Is used internally to
            distinguish an automatic build due to the ``build_on_run`` option
            from a manual ``device.build`` call.
        '''
        if self.build_on_run and direct_call:
            raise RuntimeError('You used set_device with build_on_run=True '
                               '(the default option), which will automatically '
                               'build the simulation at the first encountered '
                               'run call - do not call device.build manually '
                               'in this case. If you want to call it manually, '
                               'e.g. because you have multiple run calls, use '
                               'set_device with build_on_run=False.')
        if self.has_been_run:
>           raise RuntimeError('The network has already been built and run '
                               'before. To build several simulations in '
                               'the same script, call "device.reinit()" '
                               'and "device.activate()". Note that you '
                               'will have to set build options (e.g. the '
                               'directory) and defaultclock.dt again.')
E           RuntimeError: The network has already been built and run before. To build several simulations in the same script, call "device.reinit()" and "device.activate()". Note that you will have to set build options (e.g. the directory) and defaultclock.dt again.

../../device.py:1094: RuntimeError
_________ test_binomial_values_synapse_dynamics_fixed_and_random_seed __________

    @pytest.mark.standalone_compatible
    @pytest.mark.multiple_runs
    def test_binomial_values_synapse_dynamics_fixed_and_random_seed():
        my_f = BinomialFunction(100, 0.1, approximate=False)
        my_f_approximated = BinomialFunction(100, 0.1, approximate=True)
    
        G = NeuronGroup(10, 'z : 1')
        S = Synapses(G, G, 'dv/dt = -v/(10*ms) + 0.1*(my_f() + my_f_approximated())*xi/sqrt(ms) : 1')
        S.connect()
        mon = StateMonitor(S, 'v', record=range(100))
    
        # first run
        S.v = 0
        seed()
        run(2*defaultclock.dt)
    
        # third run
        S.v = 0
        seed()
        run(2*defaultclock.dt)
    
        # third run
        S.v = 0
        seed(13579)
        run(2*defaultclock.dt)
    
        # fourth run
        S.v = 0
        seed(13579)
        run(2*defaultclock.dt)
    
>       device.build(direct_call=False, **device.build_options)

../../tests/test_random_number_generation.py:719: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
directory = None, compile = True, run = True, debug = False, clean = False
with_output = False, disable_asserts = False, additional_source_files = None
run_args = None, direct_call = False, kwds = {}

    def build(self, directory='output',
              compile=True, run=True, debug=False, clean=False,
              with_output=True, disable_asserts=False,
              additional_source_files=None,
              run_args=None, direct_call=True, **kwds):
        '''
        Build the project
    
        TODO: more details
    
        Parameters
        ----------
        directory : str, optional
            The output directory to write the project to, any existing files
            will be overwritten. If the given directory name is ``None``, then
            a temporary directory will be used (used in the test suite to avoid
            problems when running several tests in parallel). Defaults to
            ``'output'``.
        compile : bool, optional
            Whether or not to attempt to compile the project. Defaults to
            ``True``.
        run : bool, optional
            Whether or not to attempt to run the built project if it
            successfully builds. Defaults to ``True``.
        debug : bool, optional
            Whether to compile in debug mode. Defaults to ``False``.
        with_output : bool, optional
            Whether or not to show the ``stdout`` of the built program when run.
            Output will be shown in case of compilation or runtime error.
            Defaults to ``True``.
        clean : bool, optional
            Whether or not to clean the project before building. Defaults to
            ``False``.
        additional_source_files : list of str, optional
            A list of additional ``.cu`` files to include in the build.
        direct_call : bool, optional
            Whether this function was called directly. Is used internally to
            distinguish an automatic build due to the ``build_on_run`` option
            from a manual ``device.build`` call.
        '''
        if self.build_on_run and direct_call:
            raise RuntimeError('You used set_device with build_on_run=True '
                               '(the default option), which will automatically '
                               'build the simulation at the first encountered '
                               'run call - do not call device.build manually '
                               'in this case. If you want to call it manually, '
                               'e.g. because you have multiple run calls, use '
                               'set_device with build_on_run=False.')
        if self.has_been_run:
>           raise RuntimeError('The network has already been built and run '
                               'before. To build several simulations in '
                               'the same script, call "device.reinit()" '
                               'and "device.activate()". Note that you '
                               'will have to set build options (e.g. the '
                               'directory) and defaultclock.dt again.')
E           RuntimeError: The network has already been built and run before. To build several simulations in the same script, call "device.reinit()" and "device.activate()". Note that you will have to set build options (e.g. the directory) and defaultclock.dt again.

../../device.py:1094: RuntimeError
___________ test_poisson_scalar_lambda_values_fixed_and_random_seed ____________

    @pytest.mark.standalone_compatible
    @pytest.mark.multiple_runs
    def test_poisson_scalar_lambda_values_fixed_and_random_seed():
    
        G = NeuronGroup(10, 'dv/dt = -v/(10*ms) + 0.1*poisson(5)*xi/sqrt(ms) : 1')
    
        mon = StateMonitor(G, 'v', record=True)
    
        # first run
        G.v = 0
        seed()
        run(2*defaultclock.dt)
    
        # second run
        G.v = 0
        seed()
        run(2*defaultclock.dt)
    
        # third run
        G.v = 0
        seed(13579)
        run(2*defaultclock.dt)
    
        # fourth run
        G.v = 0
        seed(13579)
        run(2*defaultclock.dt)
    
>       device.build(direct_call=False, **device.build_options)

../../tests/test_random_number_generation.py:923: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
directory = None, compile = True, run = True, debug = False, clean = False
with_output = False, disable_asserts = False, additional_source_files = None
run_args = None, direct_call = False, kwds = {}

    def build(self, directory='output',
              compile=True, run=True, debug=False, clean=False,
              with_output=True, disable_asserts=False,
              additional_source_files=None,
              run_args=None, direct_call=True, **kwds):
        '''
        Build the project
    
        TODO: more details
    
        Parameters
        ----------
        directory : str, optional
            The output directory to write the project to, any existing files
            will be overwritten. If the given directory name is ``None``, then
            a temporary directory will be used (used in the test suite to avoid
            problems when running several tests in parallel). Defaults to
            ``'output'``.
        compile : bool, optional
            Whether or not to attempt to compile the project. Defaults to
            ``True``.
        run : bool, optional
            Whether or not to attempt to run the built project if it
            successfully builds. Defaults to ``True``.
        debug : bool, optional
            Whether to compile in debug mode. Defaults to ``False``.
        with_output : bool, optional
            Whether or not to show the ``stdout`` of the built program when run.
            Output will be shown in case of compilation or runtime error.
            Defaults to ``True``.
        clean : bool, optional
            Whether or not to clean the project before building. Defaults to
            ``False``.
        additional_source_files : list of str, optional
            A list of additional ``.cu`` files to include in the build.
        direct_call : bool, optional
            Whether this function was called directly. Is used internally to
            distinguish an automatic build due to the ``build_on_run`` option
            from a manual ``device.build`` call.
        '''
        if self.build_on_run and direct_call:
            raise RuntimeError('You used set_device with build_on_run=True '
                               '(the default option), which will automatically '
                               'build the simulation at the first encountered '
                               'run call - do not call device.build manually '
                               'in this case. If you want to call it manually, '
                               'e.g. because you have multiple run calls, use '
                               'set_device with build_on_run=False.')
        if self.has_been_run:
>           raise RuntimeError('The network has already been built and run '
                               'before. To build several simulations in '
                               'the same script, call "device.reinit()" '
                               'and "device.activate()". Note that you '
                               'will have to set build options (e.g. the '
                               'directory) and defaultclock.dt again.')
E           RuntimeError: The network has already been built and run before. To build several simulations in the same script, call "device.reinit()" and "device.activate()". Note that you will have to set build options (e.g. the directory) and defaultclock.dt again.

../../device.py:1094: RuntimeError
__________ test_poisson_variable_lambda_values_fixed_and_random_seed ___________

    @pytest.mark.standalone_compatible
    @pytest.mark.multiple_runs
    def test_poisson_variable_lambda_values_fixed_and_random_seed():
    
        G = NeuronGroup(10,
                        '''l : 1
                           dv/dt = -v/(10*ms) + 0.1*poisson(l)*xi/sqrt(ms) : 1''')
        G.l = arange(10)
    
        mon = StateMonitor(G, 'v', record=True)
    
        # first run
        G.v = 0
        seed()
        run(2*defaultclock.dt)
    
        # second run
        G.v = 0
        seed()
        run(2*defaultclock.dt)
    
        # third run
        G.v = 0
        seed(13579)
        run(2*defaultclock.dt)
    
        # fourth run
        G.v = 0
        seed(13579)
        run(2*defaultclock.dt)
    
>       device.build(direct_call=False, **device.build_options)

../../tests/test_random_number_generation.py:968: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
directory = None, compile = True, run = True, debug = False, clean = False
with_output = False, disable_asserts = False, additional_source_files = None
run_args = None, direct_call = False, kwds = {}

    def build(self, directory='output',
              compile=True, run=True, debug=False, clean=False,
              with_output=True, disable_asserts=False,
              additional_source_files=None,
              run_args=None, direct_call=True, **kwds):
        '''
        Build the project
    
        TODO: more details
    
        Parameters
        ----------
        directory : str, optional
            The output directory to write the project to, any existing files
            will be overwritten. If the given directory name is ``None``, then
            a temporary directory will be used (used in the test suite to avoid
            problems when running several tests in parallel). Defaults to
            ``'output'``.
        compile : bool, optional
            Whether or not to attempt to compile the project. Defaults to
            ``True``.
        run : bool, optional
            Whether or not to attempt to run the built project if it
            successfully builds. Defaults to ``True``.
        debug : bool, optional
            Whether to compile in debug mode. Defaults to ``False``.
        with_output : bool, optional
            Whether or not to show the ``stdout`` of the built program when run.
            Output will be shown in case of compilation or runtime error.
            Defaults to ``True``.
        clean : bool, optional
            Whether or not to clean the project before building. Defaults to
            ``False``.
        additional_source_files : list of str, optional
            A list of additional ``.cu`` files to include in the build.
        direct_call : bool, optional
            Whether this function was called directly. Is used internally to
            distinguish an automatic build due to the ``build_on_run`` option
            from a manual ``device.build`` call.
        '''
        if self.build_on_run and direct_call:
            raise RuntimeError('You used set_device with build_on_run=True '
                               '(the default option), which will automatically '
                               'build the simulation at the first encountered '
                               'run call - do not call device.build manually '
                               'in this case. If you want to call it manually, '
                               'e.g. because you have multiple run calls, use '
                               'set_device with build_on_run=False.')
        if self.has_been_run:
>           raise RuntimeError('The network has already been built and run '
                               'before. To build several simulations in '
                               'the same script, call "device.reinit()" '
                               'and "device.activate()". Note that you '
                               'will have to set build options (e.g. the '
                               'directory) and defaultclock.dt again.')
E           RuntimeError: The network has already been built and run before. To build several simulations in the same script, call "device.reinit()" and "device.activate()". Note that you will have to set build options (e.g. the directory) and defaultclock.dt again.

../../device.py:1094: RuntimeError
___ test_poisson_scalar_lambda_values_synapse_dynamics_fixed_and_random_seed ___

    @pytest.mark.standalone_compatible
    @pytest.mark.multiple_runs
    def test_poisson_scalar_lambda_values_synapse_dynamics_fixed_and_random_seed():
        G = NeuronGroup(10, 'z : 1')
        S = Synapses(G, G,
                     '''dv/dt = -v/(10*ms) + 0.1*poisson(5)*xi/sqrt(ms) : 1''')
        S.connect()
        mon = StateMonitor(S, 'v', record=range(100))
    
        # first run
        S.v = 0
        seed()
        run(2*defaultclock.dt)
    
        # third run
        S.v = 0
        seed()
        run(2*defaultclock.dt)
    
        # third run
        S.v = 0
        seed(13579)
        run(2*defaultclock.dt)
    
        # fourth run
        S.v = 0
        seed(13579)
        run(2*defaultclock.dt)
    
>       device.build(direct_call=False, **device.build_options)

../../tests/test_random_number_generation.py:1085: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
directory = None, compile = True, run = True, debug = False, clean = False
with_output = False, disable_asserts = False, additional_source_files = None
run_args = None, direct_call = False, kwds = {}

    def build(self, directory='output',
              compile=True, run=True, debug=False, clean=False,
              with_output=True, disable_asserts=False,
              additional_source_files=None,
              run_args=None, direct_call=True, **kwds):
        '''
        Build the project
    
        TODO: more details
    
        Parameters
        ----------
        directory : str, optional
            The output directory to write the project to, any existing files
            will be overwritten. If the given directory name is ``None``, then
            a temporary directory will be used (used in the test suite to avoid
            problems when running several tests in parallel). Defaults to
            ``'output'``.
        compile : bool, optional
            Whether or not to attempt to compile the project. Defaults to
            ``True``.
        run : bool, optional
            Whether or not to attempt to run the built project if it
            successfully builds. Defaults to ``True``.
        debug : bool, optional
            Whether to compile in debug mode. Defaults to ``False``.
        with_output : bool, optional
            Whether or not to show the ``stdout`` of the built program when run.
            Output will be shown in case of compilation or runtime error.
            Defaults to ``True``.
        clean : bool, optional
            Whether or not to clean the project before building. Defaults to
            ``False``.
        additional_source_files : list of str, optional
            A list of additional ``.cu`` files to include in the build.
        direct_call : bool, optional
            Whether this function was called directly. Is used internally to
            distinguish an automatic build due to the ``build_on_run`` option
            from a manual ``device.build`` call.
        '''
        if self.build_on_run and direct_call:
            raise RuntimeError('You used set_device with build_on_run=True '
                               '(the default option), which will automatically '
                               'build the simulation at the first encountered '
                               'run call - do not call device.build manually '
                               'in this case. If you want to call it manually, '
                               'e.g. because you have multiple run calls, use '
                               'set_device with build_on_run=False.')
        if self.has_been_run:
>           raise RuntimeError('The network has already been built and run '
                               'before. To build several simulations in '
                               'the same script, call "device.reinit()" '
                               'and "device.activate()". Note that you '
                               'will have to set build options (e.g. the '
                               'directory) and defaultclock.dt again.')
E           RuntimeError: The network has already been built and run before. To build several simulations in the same script, call "device.reinit()" and "device.activate()". Note that you will have to set build options (e.g. the directory) and defaultclock.dt again.

../../device.py:1094: RuntimeError
__ test_poisson_variable_lambda_values_synapse_dynamics_fixed_and_random_seed __

    @pytest.mark.standalone_compatible
    @pytest.mark.multiple_runs
    def test_poisson_variable_lambda_values_synapse_dynamics_fixed_and_random_seed():
        G = NeuronGroup(10, 'z : 1')
        S = Synapses(G, G,
                     '''l : 1
                        dv/dt = -v/(10*ms) + 0.1*poisson(l)*xi/sqrt(ms) : 1''')
        S.connect()
        S.l = arange(100) / 10
        mon = StateMonitor(S, 'v', record=range(100))
    
        # first run
        S.v = 0
        seed()
        run(2*defaultclock.dt)
    
        # third run
        S.v = 0
        seed()
        run(2*defaultclock.dt)
    
        # third run
        S.v = 0
        seed(13579)
        run(2*defaultclock.dt)
    
        # fourth run
        S.v = 0
        seed(13579)
        run(2*defaultclock.dt)
    
>       device.build(direct_call=False, **device.build_options)

../../tests/test_random_number_generation.py:1130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
directory = None, compile = True, run = True, debug = False, clean = False
with_output = False, disable_asserts = False, additional_source_files = None
run_args = None, direct_call = False, kwds = {}

    def build(self, directory='output',
              compile=True, run=True, debug=False, clean=False,
              with_output=True, disable_asserts=False,
              additional_source_files=None,
              run_args=None, direct_call=True, **kwds):
        '''
        Build the project
    
        TODO: more details
    
        Parameters
        ----------
        directory : str, optional
            The output directory to write the project to, any existing files
            will be overwritten. If the given directory name is ``None``, then
            a temporary directory will be used (used in the test suite to avoid
            problems when running several tests in parallel). Defaults to
            ``'output'``.
        compile : bool, optional
            Whether or not to attempt to compile the project. Defaults to
            ``True``.
        run : bool, optional
            Whether or not to attempt to run the built project if it
            successfully builds. Defaults to ``True``.
        debug : bool, optional
            Whether to compile in debug mode. Defaults to ``False``.
        with_output : bool, optional
            Whether or not to show the ``stdout`` of the built program when run.
            Output will be shown in case of compilation or runtime error.
            Defaults to ``True``.
        clean : bool, optional
            Whether or not to clean the project before building. Defaults to
            ``False``.
        additional_source_files : list of str, optional
            A list of additional ``.cu`` files to include in the build.
        direct_call : bool, optional
            Whether this function was called directly. Is used internally to
            distinguish an automatic build due to the ``build_on_run`` option
            from a manual ``device.build`` call.
        '''
        if self.build_on_run and direct_call:
            raise RuntimeError('You used set_device with build_on_run=True '
                               '(the default option), which will automatically '
                               'build the simulation at the first encountered '
                               'run call - do not call device.build manually '
                               'in this case. If you want to call it manually, '
                               'e.g. because you have multiple run calls, use '
                               'set_device with build_on_run=False.')
        if self.has_been_run:
>           raise RuntimeError('The network has already been built and run '
                               'before. To build several simulations in '
                               'the same script, call "device.reinit()" '
                               'and "device.activate()". Note that you '
                               'will have to set build options (e.g. the '
                               'directory) and defaultclock.dt again.')
E           RuntimeError: The network has already been built and run before. To build several simulations in the same script, call "device.reinit()" and "device.activate()". Note that you will have to set build options (e.g. the directory) and defaultclock.dt again.

../../device.py:1094: RuntimeError
================== 13 failed, 682 deselected in 4.89 seconds ===================
Running standalone-specific tests
============================= test session starts ==============================
platform linux2 -- Python 2.7.18, pytest-4.6.4, py-1.10.0, pluggy-0.12.0 -- /home/denis/.conda/envs/b2c/bin/python
cachedir: .pytest_cache
rootdir: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2, inifile: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2/tests/pytest.ini
collecting ... collected 695 items / 691 deselected / 4 selected

../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_rand_randn_regex <- ../../../brian2cuda/tests/test_random_number_generation.py PASSED [ 25%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_regex <- ../../../brian2cuda/tests/test_random_number_generation.py PASSED [ 50%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_rng_occurrence_counting <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 75%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_binomial_occurrence <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [100%]

=================================== FAILURES ===================================
_________________________ test_rng_occurrence_counting _________________________

    @pytest.mark.cuda_standalone
    @pytest.mark.standalone_only
    def test_rng_occurrence_counting():
    
        set_device('cuda_standalone', directory=None)
    
        G_rand = NeuronGroup(10, '''dx/dt = rand()/ms : 1''', threshold='True', name='G_rand')
        S_rand = Synapses(G_rand, G_rand, on_pre='''x += rand()''', name='S_rand')
        S_rand.connect()
    
        G_randn = NeuronGroup(10, '''dx/dt = randn()/ms : 1''', threshold='True', name='G_randn')
        S_randn = Synapses(G_randn, G_randn, on_pre='''x += randn()''', name='S_randn')
        S_randn.connect()
    
        G_poisson = NeuronGroup(10, '''dx/dt = poisson(1)/ms : 1''', threshold='True', name='G_poisson')
        S_poisson = Synapses(G_poisson, G_poisson, on_pre='''x += poisson(1)''', name='S_poisson')
        S_poisson.connect()
    
>       run(0*ms)

../../tests/test_random_number_generation.py:129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='G_poisson'), NeuronGroup(...ame='S_rand'), Synapses(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='S_randn'), ...]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = [(Clock(dt=100. * usecond, name='defaultclock'), <weakproxy at 0x7fe4cf3916b0 to CUDAStandaloneCodeObject at 0x7fe4cf3...00. * usecond, name='defaultclock'), <weakproxy at 0x7fe4cf3befb0 to CUDAStandaloneCodeObject at 0x7fe4cf3c36d0>), ...]
obj = SynapticPathway(clock=Clock(dt=100. * usecond, name='defaultclock'), when=synapses, order=-1, name='S_randn_pre')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4cf929a10>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
----------------------------- Captured stdout call -----------------------------
('debug syn effect mode ', 'target')
('debug syn effect mode ', 'target')
('debug syn effect mode ', 'target')
----------------------------- Captured stderr call -----------------------------
WARNING    Came across an abstract code block that may not be well-defined: the outcome may depend on the order of execution. You can ignore this warning if you are sure that the order of operations does not matter. Abstract code: "x += poisson(1) (in-place)"
 [brian2.codegen.generators.base]
WARNING    Came across an abstract code block that may not be well-defined: the outcome may depend on the order of execution. You can ignore this warning if you are sure that the order of operations does not matter. Abstract code: "x += rand() (in-place)"
 [brian2.codegen.generators.base]
WARNING    Came across an abstract code block that may not be well-defined: the outcome may depend on the order of execution. You can ignore this warning if you are sure that the order of operations does not matter. Abstract code: "x += randn() (in-place)"
 [brian2.codegen.generators.base]
___________________________ test_binomial_occurrence ___________________________

    @pytest.mark.cuda_standalone
    @pytest.mark.standalone_only
    def test_binomial_occurrence():
    
        set_device('cuda_standalone', directory=None)
    
        my_f_a = BinomialFunction(100, 0.1, approximate=True)
        my_f = BinomialFunction(100, 0.1, approximate=False)
    
    
        G_my_f = NeuronGroup(10, '''dx/dt = my_f()/ms : 1''', threshold='True', name='G_my_f')
        G_my_f.x = 'my_f()'
        S_my_f = Synapses(G_my_f, G_my_f, on_pre='''x += my_f()''', name='S_my_f')
        S_my_f.connect()
    
        G_my_f_a = NeuronGroup(10, '''dx/dt = my_f_a()/ms : 1''', threshold='True', name='G_my_f_a')
        S_my_f_a = Synapses(G_my_f_a, G_my_f_a, on_pre='''x += my_f_a()''', name='S_my_f_a')
        S_my_f_a.connect()
    
>       run(0*ms)

../../tests/test_random_number_generation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7fe510e41950>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='G_my_f'), NeuronGroup(clo...ateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='G_my_f_stateupdater'), ...]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = [(Clock(dt=100. * usecond, name='defaultclock'), <weakproxy at 0x7fe4cfae6d10 to CUDAStandaloneCodeObject at 0x7fe4cff...second, name='defaultclock'), <weakproxy at 0x7fe4d0367830 to CUDAStandaloneAtomicsCodeObject at 0x7fe4cfd4a450>), ...]
obj = SynapticPathway(clock=Clock(dt=100. * usecond, name='defaultclock'), when=synapses, order=-1, name='S_my_f_pre')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7fe4cf929a10>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
----------------------------- Captured stdout call -----------------------------
('debug syn effect mode ', 'target')
('debug syn effect mode ', 'target')
----------------------------- Captured stderr call -----------------------------
WARNING    Came across an abstract code block that may not be well-defined: the outcome may depend on the order of execution. You can ignore this warning if you are sure that the order of operations does not matter. Abstract code: "x += my_f_a() (in-place)"
 [brian2.codegen.generators.base]
WARNING    Came across an abstract code block that may not be well-defined: the outcome may depend on the order of execution. You can ignore this warning if you are sure that the order of operations does not matter. Abstract code: "x += my_f() (in-place)"
 [brian2.codegen.generators.base]
============== 2 failed, 2 passed, 691 deselected in 2.41 seconds ==============
ERROR: 3/3 test suite(s) did not complete successfully (see above).
2021-08-11 09:21:33  
TARGET: CUDA_STANDALONE
2021-08-11 09:21:33  
FINISHED ALL RUNS

                     1/1 CONFIGURATIONS FAILED:
                     	1. run
                     		default preferences
Test suite took 0 h 0 m 25 s.
