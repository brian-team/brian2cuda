WARNING: clusterbot not installed. Can't notify slack.
2021-08-11 09:50:28  Turning off  compiler optimizations for fast compilation
                     Suppressing compiler warnings
                     Running with the following prefs combinations:

                     1 run with default preferences
                     

Running tests in /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2, /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/brian2cuda/tests  (including long tests)
Running Brian version 2.2.2.1+git from '/home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2'
Testing standalone

Testing standalone device "cuda_standalone"
Running standalone-compatible standard tests (single run statement)
============================= test session starts ==============================
platform linux2 -- Python 2.7.18, pytest-4.6.4, py-1.10.0, pluggy-0.12.0 -- /home/denis/.conda/envs/b2c/bin/python
cachedir: .pytest_cache
rootdir: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2, inifile: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2/tests/pytest.ini
collecting ... collected 695 items / 672 deselected / 23 selected

../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_rand <- ../../../brian2cuda/tests/test_random_number_generation.py PASSED [  4%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_values_set_synapses_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [  8%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_values_set_synapses_fixed_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 13%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_values_init_synapses_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 17%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_binomial_values_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 21%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_binomial_values_fixed_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 26%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_binomial_values_set_synapses_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 30%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_binomial_values_set_synapses_fixed_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 34%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_binomial_values_init_synapses_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 39%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_binomial_set_template_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 43%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_binomial_poisson_scalar_lambda_values_set_synapses_fixed_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 47%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_binomial_poisson_variable_lambda_values_set_synapses_fixed_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 52%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_scalar_lambda_values_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 56%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_variable_lambda_values_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 60%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_scalar_lambda_values_fixed_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 65%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_variable_lambda_values_fixed_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 69%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_scalar_lambda_values_set_synapses_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 73%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_variable_lambda_values_set_synapses_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 78%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_scalar_lambda_values_set_synapses_fixed_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 82%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_variable_lambda_values_set_synapses_fixed_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 86%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_values_init_synapses_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 91%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_scalar_lambda_set_template_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 95%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_variable_lambda_set_template_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [100%]

=================================== FAILURES ===================================
_________________ test_random_values_set_synapses_random_seed __________________

    @pytest.mark.standalone_compatible
    def test_random_values_set_synapses_random_seed():
        G = NeuronGroup(10, 'z : 1')
        S = Synapses(G, G, '''v1 : 1
                              v2 : 1''')
        S.connect()
        seed()
        S.v1 = 'rand() + randn()'
        seed()
        S.v2 = 'rand() + randn()'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:463: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), Synapses(c...ateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058b085d0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
__________________ test_random_values_set_synapses_fixed_seed __________________

    @pytest.mark.standalone_compatible
    def test_random_values_set_synapses_fixed_seed():
        G = NeuronGroup(10, 'z : 1')
        S = Synapses(G, G, '''v1 : 1
                              v2 : 1''')
        S.connect()
        seed(12345678)
        S.v1 = 'rand() + randn()'
        seed(12345678)
        S.v2 = 'rand() + randn()'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:479: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_1'), Synapses...eUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058b085d0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
____________ test_random_values_init_synapses_fixed_and_random_seed ____________

    @pytest.mark.standalone_compatible
    def test_random_values_init_synapses_fixed_and_random_seed():
        G = NeuronGroup(10, 'z : 1')
    
        seed()
        S1 = Synapses(G, G)
        S1.connect('randn() + 0.5 < rand()')
    
        seed(12345678)
        S2 = Synapses(G, G)
        S2.connect('randn() + 0.5 < rand()')
    
        seed()
        S3 = Synapses(G, G)
        S3.connect('randn() + 0.5 < rand()')
    
        seed(12345678)
        S4 = Synapses(G, G)
        S4.connect('randn() + 0.5 < rand()')
    
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:549: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), Synapses(c...ateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058b085d0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
_______________________ test_binomial_values_random_seed _______________________

    @pytest.mark.standalone_compatible
    def test_binomial_values_random_seed():
        G = NeuronGroup(100, '''v1 : 1
                                v2 : 1''')
        my_f = BinomialFunction(100, 0.1, approximate=False)
        my_f_approximated = BinomialFunction(100, 0.1, approximate=True)
        seed()
        G.v1 = 'my_f() + my_f_approximated()'
        seed()
        G.v2 = 'my_f() + my_f_approximated()'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:580: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_2'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_2_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_2_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058b085d0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
_______________________ test_binomial_values_fixed_seed ________________________

    @pytest.mark.standalone_compatible
    def test_binomial_values_fixed_seed():
        G = NeuronGroup(100, '''v1 : 1
                                v2 : 1''')
        my_f = BinomialFunction(100, 0.1, approximate=False)
        my_f_approximated = BinomialFunction(100, 0.1, approximate=True)
        seed(12345678)
        G.v1 = 'my_f() + my_f_approximated()'
        seed(12345678)
        G.v2 = 'my_f() + my_f_approximated()'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:596: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058b085d0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
________________ test_binomial_values_set_synapses_random_seed _________________

    @pytest.mark.standalone_compatible
    def test_binomial_values_set_synapses_random_seed():
        G = NeuronGroup(10, 'z : 1')
        S = Synapses(G, G, '''v1 : 1
                              v2 : 1''')
        S.connect()
    
        my_f = BinomialFunction(100, 0.1, approximate=False)
        my_f_approximated = BinomialFunction(100, 0.1, approximate=True)
    
        seed()
        S.v1 = 'my_f() + my_f_approximated()'
        seed()
        S.v2 = 'my_f() + my_f_approximated()'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:661: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_1'), Synapses...eUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058b085d0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
_________________ test_binomial_values_set_synapses_fixed_seed _________________

    @pytest.mark.standalone_compatible
    def test_binomial_values_set_synapses_fixed_seed():
        G = NeuronGroup(10, 'z : 1')
        S = Synapses(G, G, '''v1 : 1
                              v2 : 1''')
        S.connect()
    
        my_f = BinomialFunction(100, 0.1, approximate=False)
        my_f_approximated = BinomialFunction(100, 0.1, approximate=True)
    
        seed(12345678)
        S.v1 = 'my_f() + my_f_approximated()'
        seed(12345678)
        S.v2 = 'my_f() + my_f_approximated()'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:681: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), Synapses(c...ateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058a6bfd0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
___________ test_binomial_values_init_synapses_fixed_and_random_seed ___________

    @pytest.mark.standalone_compatible
    def test_binomial_values_init_synapses_fixed_and_random_seed():
        G = NeuronGroup(10, 'z : 1')
    
        my_f = BinomialFunction(100, 0.1, approximate=False)
        my_f_approximated = BinomialFunction(100, 0.1, approximate=True)
    
        seed()
        S1 = Synapses(G, G)
        S1.connect('my_f() < my_f_approximated()')
    
        seed(12345678)
        S2 = Synapses(G, G)
        S2.connect('my_f() < my_f_approximated()')
    
        seed()
        S3 = Synapses(G, G)
        S3.connect('my_f() < my_f_approximated()')
    
        seed(12345678)
        S4 = Synapses(G, G)
        S4.connect('my_f() < my_f_approximated()')
    
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:757: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_2'), Synapses...eUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_2_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_2_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058a6bfd0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
________________ test_random_binomial_set_template_random_seed _________________

    @pytest.mark.standalone_compatible
    def test_random_binomial_set_template_random_seed():
        G = NeuronGroup(10, '''v1 : 1
                               v2 : 1''')
        my_f = BinomialFunction(100, 0.1, approximate=False)
        my_f_approximated = BinomialFunction(100, 0.1, approximate=True)
    
        seed()
        G.v1[:8] = 'rand() + randn() + my_f() + my_f_approximated()'
        seed()
        G.v2[:8] = 'rand() + randn() + my_f() + my_f_approximated()'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058a6bfd0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
__ test_random_binomial_poisson_scalar_lambda_values_set_synapses_fixed_seed ___

    @pytest.mark.standalone_compatible
    def test_random_binomial_poisson_scalar_lambda_values_set_synapses_fixed_seed():
        G = NeuronGroup(10, '''v1 : 1
                               v2 : 1''')
        my_f = BinomialFunction(100, 0.1, approximate=False)
        my_f_approximated = BinomialFunction(100, 0.1, approximate=True)
    
        seed(12345678)
        G.v1[:8] = 'rand() + randn() + my_f() + my_f_approximated() + poisson(5)'
        seed(12345678)
        G.v2[:8] = 'rand() + randn() + my_f() + my_f_approximated() + poisson(5)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:804: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_1'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058a6bfd0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
_ test_random_binomial_poisson_variable_lambda_values_set_synapses_fixed_seed __

    @pytest.mark.standalone_compatible
    def test_random_binomial_poisson_variable_lambda_values_set_synapses_fixed_seed():
        G = NeuronGroup(10, '''v1 : 1
                               v2 : 1
                               l  : 1''')
        G.l = arange(10)
        my_f = BinomialFunction(100, 0.1, approximate=False)
        my_f_approximated = BinomialFunction(100, 0.1, approximate=True)
    
        seed(12345678)
        G.v1[:8] = 'rand() + randn() + my_f() + my_f_approximated() + poisson(l)'
        seed(12345678)
        G.v2[:8] = 'rand() + randn() + my_f() + my_f_approximated() + poisson(l)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:823: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058a6bfd0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
________________ test_poisson_scalar_lambda_values_random_seed _________________

    @pytest.mark.standalone_compatible
    def test_poisson_scalar_lambda_values_random_seed():
        G = NeuronGroup(100, '''v1 : 1
                                v2 : 1''')
        seed()
        G.v1 = 'poisson(5)'
        seed()
        G.v2 = 'poisson(5)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:840: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_2'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_2_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_2_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058a6bfd0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
_______________ test_poisson_variable_lambda_values_random_seed ________________

    @pytest.mark.standalone_compatible
    def test_poisson_variable_lambda_values_random_seed():
        G = NeuronGroup(100, '''v1 : 1
                                v2 : 1
                                x1 : 1
                                x2 : 1
                                l  : 1''')
        G.l = arange(100) / 10
        seed()
        G.v1 = 'poisson(l)'
        seed()
        G.v2 = 'poisson(l)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:858: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058a6bfd0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
_________________ test_poisson_scalar_lambda_values_fixed_seed _________________

    @pytest.mark.standalone_compatible
    def test_poisson_scalar_lambda_values_fixed_seed():
        G = NeuronGroup(100, '''v1 : 1
                                v2 : 1''')
        seed(12345678)
        G.v1 = 'poisson(5)'
        seed(12345678)
        G.v2 = 'poisson(5)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:872: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_1'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058a6bfd0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
________________ test_poisson_variable_lambda_values_fixed_seed ________________

    @pytest.mark.standalone_compatible
    def test_poisson_variable_lambda_values_fixed_seed():
        G = NeuronGroup(100, '''v1 : 1
                                v2 : 1
                                l  : 1''')
        G.l = arange(100) / 10
        seed(12345678)
        G.v1 = 'poisson(l)'
        seed(12345678)
        G.v2 = 'poisson(l)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:888: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058a6bfd0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
__________ test_poisson_scalar_lambda_values_set_synapses_random_seed __________

    @pytest.mark.standalone_compatible
    def test_poisson_scalar_lambda_values_set_synapses_random_seed():
        G = NeuronGroup(10, 'z : 1')
        S = Synapses(G, G, '''v1 : 1
                              v2 : 1''')
        S.connect()
    
        seed()
        S.v1 = 'poisson(5)'
        seed()
        S.v2 = 'poisson(5)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:994: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_2'), Synapses...eUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_2_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_2_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058a6bfd0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
_________ test_poisson_variable_lambda_values_set_synapses_random_seed _________

    @pytest.mark.standalone_compatible
    def test_poisson_variable_lambda_values_set_synapses_random_seed():
        G = NeuronGroup(10, 'z : 1')
        S = Synapses(G, G, '''v1 : 1
                              v2 : 1
                              l  : 1''')
        S.connect()
        S.l = arange(100) / 10
    
        seed()
        S.v1 = 'poisson(l)'
        seed()
        S.v2 = 'poisson(l)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:1013: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), Synapses(c...ateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058a6bfd0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
__________ test_poisson_scalar_lambda_values_set_synapses_fixed_seed ___________

    @pytest.mark.standalone_compatible
    def test_poisson_scalar_lambda_values_set_synapses_fixed_seed():
        G = NeuronGroup(10, 'z : 1')
        S = Synapses(G, G, '''v1 : 1
                              v2 : 1''')
        S.connect()
    
        seed(12345678)
        S.v1 = 'poisson(5)'
        seed(12345678)
        S.v2 = 'poisson(5)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:1030: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_1'), Synapses...eUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058a6bfd0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
_________ test_poisson_variable_lambda_values_set_synapses_fixed_seed __________

    @pytest.mark.standalone_compatible
    def test_poisson_variable_lambda_values_set_synapses_fixed_seed():
        G = NeuronGroup(10, 'z : 1')
        S = Synapses(G, G, '''v1 : 1
                              v2 : 1
                              l  : 1''')
        S.connect()
        S.l = arange(100) / 10
    
        seed(12345678)
        S.v1 = 'poisson(l)'
        seed(12345678)
        S.v2 = 'poisson(l)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:1049: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), Synapses(c...ateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058a6bfd0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
___________ test_poisson_values_init_synapses_fixed_and_random_seed ____________

    @pytest.mark.standalone_compatible
    def test_poisson_values_init_synapses_fixed_and_random_seed():
        G = NeuronGroup(10, 'l : 1')
        G.l = arange(10)
    
        seed()
        S1 = Synapses(G, G)
        S1.connect('poisson(5) < poisson(l_post + l_pre)')
    
        seed(12345678)
        S2 = Synapses(G, G)
        S2.connect('poisson(5) < poisson(l_post + l_pre)')
    
        seed()
        S3 = Synapses(G, G)
        S3.connect('poisson(5) < poisson(l_post + l_pre)')
    
        seed(12345678)
        S4 = Synapses(G, G)
        S4.connect('poisson(5) < poisson(l_post + l_pre)')
    
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:1166: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_2'), Synapses...eUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_2_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_2_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058a6bfd0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
_____________ test_poisson_scalar_lambda_set_template_random_seed ______________

    @pytest.mark.standalone_compatible
    def test_poisson_scalar_lambda_set_template_random_seed():
        G = NeuronGroup(10, '''v1 : 1
                               v2 : 1''')
    
        seed()
        G.v1[:8] = 'rand() + randn() + poisson(5)'
        seed()
        G.v2[:8] = 'rand() + randn() + poisson(5)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:1194: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058a6bfd0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
____________ test_poisson_variable_lambda_set_template_random_seed _____________

    @pytest.mark.standalone_compatible
    def test_poisson_variable_lambda_set_template_random_seed():
        G = NeuronGroup(10, '''v1 : 1
                               v2 : 1
                               l  : 1''')
    
        G.l = arange(10)
        seed()
        G.v1[:8] = 'rand() + randn() + poisson(l)'
        seed()
        G.v2[:8] = 'rand() + randn() + poisson(l)'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:1211: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7f10995d57d0>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup_1'), StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_1_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7f1058a6bfd0>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
=============================== warnings summary ===============================
/home/denis/.conda/envs/b2c/lib/python2.7/site-packages/_pytest/mark/structures.py:334
  /home/denis/.conda/envs/b2c/lib/python2.7/site-packages/_pytest/mark/structures.py:334: PytestUnknownMarkWarning: Unknown pytest.mark.cuda_standalone - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html
    PytestUnknownMarkWarning,

-- Docs: https://docs.pytest.org/en/latest/warnings.html
======= 22 failed, 1 passed, 672 deselected, 1 warnings in 15.70 seconds =======
Running standalone-compatible standard tests (multiple run statements)
============================= test session starts ==============================
platform linux2 -- Python 2.7.18, pytest-4.6.4, py-1.10.0, pluggy-0.12.0 -- /home/denis/.conda/envs/b2c/bin/python
cachedir: .pytest_cache
rootdir: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2, inifile: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2/tests/pytest.ini
collecting ... collected 695 items / 682 deselected / 13 selected

../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_number_generation_with_multiple_runs <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [  7%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_values_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 15%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_scalar_values_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 23%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_vectorized_values_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 30%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_values_codeobject_every_tick <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 38%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_binomial_values <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 46%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_values_synapse_dynamics_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 53%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_binomial_values_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 61%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_binomial_values_synapse_dynamics_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 69%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_scalar_lambda_values_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 76%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_variable_lambda_values_fixed_and_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py Test suite took 0 h 0 m 21 s.
