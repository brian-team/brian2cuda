WARNING: clusterbot not installed. Can't notify slack.
2021-08-11 11:29:03  Turning off  compiler optimizations for fast compilation
                     Suppressing compiler warnings
                     Running with the following prefs combinations:

                     1 run with default preferences
                     

Running tests in /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2, /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/brian2cuda/tests  (including long tests)
Running Brian version 2.2.2.1+git from '/home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2'
Testing standalone

Testing standalone device "cuda_standalone"
Running standalone-compatible standard tests (single run statement)
============================= test session starts ==============================
platform linux2 -- Python 2.7.18, pytest-4.6.4, py-1.10.0, pluggy-0.12.0 -- /home/denis/.conda/envs/b2c/bin/python
cachedir: .pytest_cache
rootdir: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2, inifile: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2/tests/pytest.ini
collecting ... collected 692 items / 669 deselected / 23 selected

../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_rand <- ../../../brian2cuda/tests/test_random_number_generation.py PASSED [  4%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_values_set_synapses_random_seed <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [  8%]

=================================== FAILURES ===================================
_________________ test_random_values_set_synapses_random_seed __________________

    @pytest.mark.standalone_compatible
    def test_random_values_set_synapses_random_seed():
        G = NeuronGroup(10, 'z : 1')
        S = Synapses(G, G, '''v1 : 1
                              v2 : 1''')
        S.connect()
        seed()
        S.v1 = 'rand() + randn()'
        seed()
        S.v2 = 'rand() + randn()'
>       run(0*ms)  # for standalone

../../tests/test_random_number_generation.py:463: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7ff59c9bee90>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='neurongroup'), Synapses(c...ateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = []
obj = StateUpdater(clock=Clock(dt=100. * usecond, name='defaultclock'), when=groups, order=0, name='neurongroup_stateupdater')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7ff55c0ad210>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
=============================== warnings summary ===============================
/home/denis/.conda/envs/b2c/lib/python2.7/site-packages/_pytest/mark/structures.py:334
  /home/denis/.conda/envs/b2c/lib/python2.7/site-packages/_pytest/mark/structures.py:334: PytestUnknownMarkWarning: Unknown pytest.mark.cuda_standalone - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html
    PytestUnknownMarkWarning,

-- Docs: https://docs.pytest.org/en/latest/warnings.html
======= 1 failed, 1 passed, 669 deselected, 1 warnings in 13.24 seconds ========
Running standalone-compatible standard tests (multiple run statements)
============================= test session starts ==============================
platform linux2 -- Python 2.7.18, pytest-4.6.4, py-1.10.0, pluggy-0.12.0 -- /home/denis/.conda/envs/b2c/bin/python
cachedir: .pytest_cache
rootdir: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2, inifile: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2/tests/pytest.ini
collecting ... collected 692 items / 679 deselected / 13 selected

../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_random_number_generation_with_multiple_runs <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [  7%]

=================================== FAILURES ===================================
_______________ test_random_number_generation_with_multiple_runs _______________

    @pytest.mark.standalone_compatible
    @pytest.mark.multiple_runs
    def test_random_number_generation_with_multiple_runs():
        G = NeuronGroup(1000, 'dv/dt = rand() : second')
        mon = StateMonitor(G, 'v', record=True)
    
        run(1*defaultclock.dt)
        run(2*defaultclock.dt)
>       device.build(direct_call=False, **device.build_options)

../../tests/test_random_number_generation.py:216: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7ff59c9bee90>
directory = None, compile = True, run = True, debug = False, clean = False
with_output = False, disable_asserts = False, additional_source_files = None
run_args = None, direct_call = False, kwds = {}

    def build(self, directory='output',
              compile=True, run=True, debug=False, clean=False,
              with_output=True, disable_asserts=False,
              additional_source_files=None,
              run_args=None, direct_call=True, **kwds):
        '''
        Build the project
    
        TODO: more details
    
        Parameters
        ----------
        directory : str, optional
            The output directory to write the project to, any existing files
            will be overwritten. If the given directory name is ``None``, then
            a temporary directory will be used (used in the test suite to avoid
            problems when running several tests in parallel). Defaults to
            ``'output'``.
        compile : bool, optional
            Whether or not to attempt to compile the project. Defaults to
            ``True``.
        run : bool, optional
            Whether or not to attempt to run the built project if it
            successfully builds. Defaults to ``True``.
        debug : bool, optional
            Whether to compile in debug mode. Defaults to ``False``.
        with_output : bool, optional
            Whether or not to show the ``stdout`` of the built program when run.
            Output will be shown in case of compilation or runtime error.
            Defaults to ``True``.
        clean : bool, optional
            Whether or not to clean the project before building. Defaults to
            ``False``.
        additional_source_files : list of str, optional
            A list of additional ``.cu`` files to include in the build.
        direct_call : bool, optional
            Whether this function was called directly. Is used internally to
            distinguish an automatic build due to the ``build_on_run`` option
            from a manual ``device.build`` call.
        '''
        if self.build_on_run and direct_call:
            raise RuntimeError('You used set_device with build_on_run=True '
                               '(the default option), which will automatically '
                               'build the simulation at the first encountered '
                               'run call - do not call device.build manually '
                               'in this case. If you want to call it manually, '
                               'e.g. because you have multiple run calls, use '
                               'set_device with build_on_run=False.')
        if self.has_been_run:
>           raise RuntimeError('The network has already been built and run '
                               'before. To build several simulations in '
                               'the same script, call "device.reinit()" '
                               'and "device.activate()". Note that you '
                               'will have to set build options (e.g. the '
                               'directory) and defaultclock.dt again.')
E           RuntimeError: The network has already been built and run before. To build several simulations in the same script, call "device.reinit()" and "device.activate()". Note that you will have to set build options (e.g. the directory) and defaultclock.dt again.

../../device.py:1094: RuntimeError
=================== 1 failed, 679 deselected in 1.70 seconds ===================
Running standalone-specific tests
============================= test session starts ==============================
platform linux2 -- Python 2.7.18, pytest-4.6.4, py-1.10.0, pluggy-0.12.0 -- /home/denis/.conda/envs/b2c/bin/python
cachedir: .pytest_cache
rootdir: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2, inifile: /home/denis/tubcloud/home/projects/brian2cuda/brian2cuda_repository/frozen_repos/brian2/brian2/tests/pytest.ini
collecting ... collected 692 items / 688 deselected / 4 selected

../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_rand_randn_regex <- ../../../brian2cuda/tests/test_random_number_generation.py PASSED [ 25%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_poisson_regex <- ../../../brian2cuda/tests/test_random_number_generation.py PASSED [ 50%]
../../../frozen_repos/brian2/brian2/test_random_number_generation.py::test_rng_occurrence_counting <- ../../../brian2cuda/tests/test_random_number_generation.py FAILED [ 75%]

=================================== FAILURES ===================================
_________________________ test_rng_occurrence_counting _________________________

    @pytest.mark.cuda_standalone
    @pytest.mark.standalone_only
    def test_rng_occurrence_counting():
    
        set_device('cuda_standalone', directory=None)
    
        G_rand = NeuronGroup(10, '''dx/dt = rand()/ms : 1''', threshold='True', name='G_rand')
        S_rand = Synapses(G_rand, G_rand, on_pre='''x += rand()''', name='S_rand')
        S_rand.connect()
    
        G_randn = NeuronGroup(10, '''dx/dt = randn()/ms : 1''', threshold='True', name='G_randn')
        S_randn = Synapses(G_randn, G_randn, on_pre='''x += randn()''', name='S_randn')
        S_randn.connect()
    
        G_poisson = NeuronGroup(10, '''dx/dt = poisson(1)/ms : 1''', threshold='True', name='G_poisson')
        S_poisson = Synapses(G_poisson, G_poisson, on_pre='''x += poisson(1)''', name='S_poisson')
        S_poisson.connect()
    
>       run(0*ms)

../../tests/test_random_number_generation.py:129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../frozen_repos/brian2/brian2/units/fundamentalunits.py:2392: in new_f
    result = f(*args, **kwds)
../../../frozen_repos/brian2/brian2/core/magic.py:374: in run
    namespace=namespace, profile=profile, level=2+level)
../../../frozen_repos/brian2/brian2/core/magic.py:232: in run
    namespace=namespace, profile=profile, level=level+1)
../../../frozen_repos/brian2/brian2/core/base.py:278: in device_override_decorated_function
    return getattr(curdev, name)(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <brian2cuda.device.CUDAStandaloneDevice object at 0x7ff59c9bee90>
net = MagicNetwork(), duration = 0. * second, report = None
report_period = 10. * second
namespace = {'@py_builtins': <module '__builtin__' (built-in)>, '@pytest_ar': <module '_pytest.assertion.rewrite' from '/home/deni...-packages/_pytest/assertion/rewrite.pyc'>, 'ALLOW_THREADS': 1, 'Annotation': <class 'matplotlib.text.Annotation'>, ...}
profile = False, level = 3, kwds = {}
all_objects = [NeuronGroup(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='G_poisson'), NeuronGroup(...ame='S_rand'), Synapses(clock=Clock(dt=100. * usecond, name='defaultclock'), when=start, order=0, name='S_randn'), ...]
t_end = 0. * second, clock = Clock(dt=100. * usecond, name='defaultclock')
code_objects = [(Clock(dt=100. * usecond, name='defaultclock'), <weakproxy at 0x7ff55c003530 to CUDAStandaloneCodeObject at 0x7ff59c9...00. * usecond, name='defaultclock'), <weakproxy at 0x7ff55b821c50 to CUDAStandaloneCodeObject at 0x7ff55c0c6d50>), ...]
obj = SynapticPathway(clock=Clock(dt=100. * usecond, name='defaultclock'), when=synapses, order=-1, name='S_randn_pre')
codeobj = <brian2cuda.codeobject.CUDAStandaloneCodeObject object at 0x7ff55ba13d10>
standard_code = '\n        void report_progress(const double elapsed, const double completed, const double start, const double duratio...ning.";\n                }\n            }\n\n            %STREAMNAME% << std::endl << std::flush;\n        }\n        '

    def network_run(self, net, duration, report=None, report_period=10*second,
                    namespace=None, profile=False, level=0, **kwds):
        ###################################################
        ### This part is copied from CPPStandaoneDevice ###
        ###################################################
        if kwds:
            logger.warn(('Unsupported keyword argument(s) provided for run: '
                         '%s') % ', '.join(kwds.keys()))
        # We store this as an instance variable for later access by the
        # `code_object` method
        self.enable_profiling = profile
    
        all_objects = net.sorted_objects
        net._clocks = {obj.clock for obj in all_objects}
        t_end = net.t+duration
        for clock in net._clocks:
            clock.set_interval(net.t, t_end)
    
        # Get the local namespace
        if namespace is None:
            namespace = get_local_namespace(level=level+2)
    
        net.before_run(namespace)
    
        self.clocks.update(net._clocks)
        net.t_ = float(t_end)
    
        # TODO: remove this horrible hack
        for clock in self.clocks:
            if clock.name=='clock':
                clock._name = '_clock'
    
        # Extract all the CodeObjects
        # Note that since we ran the Network object, these CodeObjects will be sorted into the right
        # running order, assuming that there is only one clock
        code_objects = []
        for obj in all_objects:
            if obj.active:
                for codeobj in obj._code_objects:
                    code_objects.append((obj.clock, codeobj))
    
        # Code for a progress reporting function
        standard_code = '''
        void report_progress(const double elapsed, const double completed, const double start, const double duration)
        {
            if (completed == 0.0)
            {
                %STREAMNAME% << "Starting simulation at t=" << start << " s for duration " << duration << " s";
            } else
            {
                %STREAMNAME% << completed*duration << " s (" << (int)(completed*100.) << "%) simulated in " << elapsed << " s";
                if (completed < 1.0)
                {
                    const int remaining = (int)((1-completed)/completed*elapsed+0.5);
                    %STREAMNAME% << ", estimated " << remaining << " s remaining.";
                }
            }
    
            %STREAMNAME% << std::endl << std::flush;
        }
        '''
        if report is None:
            report_func = ''
        elif report == 'text' or report == 'stdout':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cout')
        elif report == 'stderr':
            report_func = standard_code.replace('%STREAMNAME%', 'std::cerr')
        elif isinstance(report, basestring):
            report_func = '''
            void report_progress(const double elapsed, const double completed, const double start, const double duration)
            {
            %REPORT%
            }
            '''.replace('%REPORT%', report)
        else:
            raise TypeError(('report argument has to be either "text", '
                             '"stdout", "stderr", or the code for a report '
                             'function'))
    
        if report_func != '':
            if self.report_func != '' and report_func != self.report_func:
                raise NotImplementedError('The CUDA standalone device does not '
                                          'support multiple report functions, '
                                          'each run has to use the same (or '
                                          'none).')
            self.report_func = report_func
    
        if report is not None:
            report_call = 'report_progress'
        else:
            report_call = 'NULL'
    
        ##############################################################
        ### From here on the code differs from CPPStandaloneDevice ###
        ##############################################################
    
        # For each codeobject of this run check if it uses rand, randn, poisson or
        # binomials. Store these as attributes of the codeobject and create
        # lists of codeobjects that use rand, randn, poisson or binomials. This only
        # checks codeobject in the network, meaning only the ones running every
        # clock cycle.
        # self.codeobjects_with_rng["host_api"]["per_run"] is a list (one per run) of defaultdicts
        # with keys 'rand', 'randn', 'poisson_<idx>' and values being lists of
        # codeobjects.
        self.codeobjects_with_rng["host_api"]["per_run"].append(defaultdict(list))
        run_idx = -1  # last list index
    
        # Count random number ocurrences in codeobjects run every tick
        for _, co in code_objects:  # (clock, code_object)
            prepare_codeobj_code_for_rng(co)
            if co.rng_calls["rand"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['rand'].append(co)
            if co.rng_calls["randn"] > 0:
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx]['randn'].append(co)
            for poisson_name, lamda in co.poisson_lamdas.items():
                self.all_poisson_lamdas[co.name][poisson_name] = lamda
                self.codeobjects_with_rng["host_api"]["per_run"][run_idx][poisson_name].append(co)
            if co.needs_curand_states:
                if co not in self.codeobjects_with_rng["device_api"]["every_tick"]:
                    self.codeobjects_with_rng["device_api"]["every_tick"].append(co)
    
        # To profile SpeedTests, we need to be able to set `profile` in
        # `set_device`. Here we catch that case.
        if 'profile' in self.build_options:
            build_profile = self.build_options.pop('profile')
            if build_profile:
                self.enable_profiling = True
    
        # Generate the updaters
        run_lines = []
        run_lines.append('{net.name}.clear();'.format(net=net))
    
        # create all random numbers needed for the next clock cycle
        for clock in net._clocks:
            run_lines.append('{net.name}.add(&{clock.name}, _run_random_number_buffer);'.format(clock=clock, net=net))
    
        all_clocks = set()
        for clock, codeobj in code_objects:
            run_lines.append('{net.name}.add(&{clock.name}, _run_{codeobj.name});'.format(clock=clock,
                                                                                          net=net, codeobj=codeobj))
            all_clocks.add(clock)
    
        # Under some rare circumstances (e.g. a NeuronGroup only defining a
        # subexpression that is used by other groups (via linking, or recorded
        # by a StateMonitor) *and* not calculating anything itself *and* using a
        # different clock than all other objects) a clock that is not used by
        # any code object should nevertheless advance during the run. We include
        # such clocks without a code function in the network.
        for clock in net._clocks:
            if clock not in all_clocks:
                run_lines.append('{net.name}.add(&{clock.name}, NULL);'.format(clock=clock, net=net))
    
        # In our benchmark scripts we run one example `nvprof` run,
        # which is informative especially when not running in profile
        # mode. In order to have the `nvprof` call only profile the
        # kernels which are run every timestep, we add
        # `cudaProfilerStart()`, `cudaDeviceSynchronize()` and
        # `cudaProfilerStop()`. But this might be confusing for anybody
        # who runs `nvprof` on their generated code, since it will not
        # report any profiling info about kernels, that initialise
        # things only once in the beginning? Maybe get rid of it in a
        # release version? (TODO)
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStart());')
        # run everything that is run on a clock
        run_lines.append('{net.name}.run({duration!r}, {report_call}, {report_period!r});'.format(net=net,
                                                                                              duration=float(duration),
                                                                                              report_call=report_call,
                                                                                              report_period=float(report_period)))
        # for multiple runs, the random number buffer needs to be reset
        run_lines.append('random_number_buffer.run_finished();')
        # nvprof stuff
        run_lines.append('CUDA_SAFE_CALL(cudaDeviceSynchronize());')
        run_lines.append('CUDA_SAFE_CALL(cudaProfilerStop());')
    
        self.main_queue.append(('run_network', (net, run_lines)))
    
        # Manually set the cache for the clocks, simulation scripts might
        # want to access the time (which has been set in code and is therefore
        # not accessible by the normal means until the code has been built and
        # run)
        for clock in net._clocks:
            self.array_cache[clock.variables['timestep']] = np.array([clock._i_end])
            self.array_cache[clock.variables['t']] = np.array([clock._i_end * clock.dt_])
    
        # Initialize eventspaces with -1 before the network runs
        for codeobj in self.code_objects.values():
            if codeobj.template_name == "threshold" or codeobj.template_name == "spikegenerator":
                for key in codeobj.variables.iterkeys():
                    if key.endswith('space'):  # get the correct eventspace name
                        eventspace_name = self.get_array_name(codeobj.variables[key], False)
                        # In case of custom scheduling, the thresholder might come after synapses or monitors
                        # and needs to be initialized in the beginning of the simulation
    
                        # See generate_main_source() for main_queue formats
    
                        # Initialize entire eventspace array with -1 at beginning of main
                        self.main_queue.insert(
                            0,  # list insert position
                            # func            , (arrayname, value, is_dynamic)
                            ('set_by_constant', (eventspace_name, -1, False))
                        )
                        # Set the last value (index N) in the eventspace array to 0 (-> event counter)
                        self.main_queue.insert(
                            1,  # list insert position
                            (
                                'set_by_single_value',  # func
                                # arrayname     , item,                                , value
                                (eventspace_name, "_num_{} - 1".format(eventspace_name), 0)
                            )
                        )
    
        if self.build_on_run:
            if self.has_been_run:
>               raise RuntimeError('The network has already been built and run '
                                   'before. Use set_device with '
                                   'build_on_run=False and an explicit '
                                   'device.build call to use multiple run '
                                   'statements with this device.')
E               RuntimeError: The network has already been built and run before. Use set_device with build_on_run=False and an explicit device.build call to use multiple run statements with this device.

../../device.py:1487: RuntimeError
----------------------------- Captured stdout call -----------------------------
('debug syn effect mode ', 'target')
('debug syn effect mode ', 'target')
('debug syn effect mode ', 'target')
----------------------------- Captured stderr call -----------------------------
WARNING    Came across an abstract code block that may not be well-defined: the outcome may depend on the order of execution. You can ignore this warning if you are sure that the order of operations does not matter. Abstract code: "x += poisson(1) (in-place)"
 [brian2.codegen.generators.base]
WARNING    Came across an abstract code block that may not be well-defined: the outcome may depend on the order of execution. You can ignore this warning if you are sure that the order of operations does not matter. Abstract code: "x += rand() (in-place)"
 [brian2.codegen.generators.base]
WARNING    Came across an abstract code block that may not be well-defined: the outcome may depend on the order of execution. You can ignore this warning if you are sure that the order of operations does not matter. Abstract code: "x += randn() (in-place)"
 [brian2.codegen.generators.base]
============== 1 failed, 2 passed, 688 deselected in 1.97 seconds ==============
ERROR: 3/3 test suite(s) did not complete successfully (see above).
2021-08-11 11:29:20  
TARGET: CUDA_STANDALONE
2021-08-11 11:29:20  
FINISHED ALL RUNS

                     1/1 CONFIGURATIONS FAILED:
                     	1. run
                     		default preferences
Test suite took 0 h 0 m 18 s.
